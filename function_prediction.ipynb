{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e62c03ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4097\n",
      "['0', '12', '16', '21', '23', '27', '29', '30', '32', '33', '34', '35', '36', '37', '38', '39', '7155', '7156', '7157', '7158', '7160', '7161', '7162', '7163', '7291', '7293', '7294', '7297', '8']\n",
      "[('362663.ECP_4197', 0.806), ('362663.ECP_1663', 0.714), ('362663.ECP_3273', 0.821), ('362663.ECP_3384', 0.809), ('362663.ECP_2610', 0.81), ('362663.ECP_0201', 0.875), ('362663.ECP_3408', 0.886), ('362663.ECP_0199', 0.865), ('362663.ECP_3272', 0.713), ('362663.ECP_3431', 0.858), ('362663.ECP_3379', 0.889), ('362663.ECP_2620', 0.802), ('362663.ECP_3405', 0.879)]\n"
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import copy\n",
    "from ipynb.fs.full.data_explore import DataExplorer\n",
    "from collections import Counter\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b45aae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionPrediction():\n",
    "    def __init__(self, organism_name):\n",
    "        # get all the annotation, adjacency list data from the explorer class\n",
    "        self.data_explorer = DataExplorer(organism_name)\n",
    "        \n",
    "    def get_nborhood(self, protein, r, df=\"set\"):\n",
    "        # to get r-neighborhood of protein\n",
    "        if r == 1:\n",
    "            fnl_nborhood = [\n",
    "                nbor for (nbor, score) in self.data_explorer.adj_list[protein]\n",
    "            ]\n",
    "\n",
    "            if df == \"set\":\n",
    "                return set(fnl_nborhood), set(fnl_nborhood)\n",
    "            else:\n",
    "                return fnl_nborhood, fnl_nborhood\n",
    "\n",
    "        accum, last_nborhood = get_nborhood(protein, r - 1, df, include_levels)\n",
    "\n",
    "        fnl_nborhood = []\n",
    "\n",
    "        for protein in last_nborhood:\n",
    "            for (nbor, score) in self.data_explorer.adj_list[protein]:\n",
    "                fnl_nborhood.append(nbor)\n",
    "\n",
    "        if df == \"set\":\n",
    "            return set(accum + fnl_nborhood), set(fnl_nborhood)\n",
    "        else:\n",
    "            return accum + fnl_nborhood, fnl_nborhood\n",
    "        \n",
    "    def majority_rule(self, protein_id_list, r=1):\n",
    "        # input: protein list, adjacency list graph representation\n",
    "        # output: cluster assignment for each protein in list based on the majority rule of protein's neighbors\n",
    "        \n",
    "        \n",
    "        # this was me trying to come up with a way to get specific labels for clusters but then realizing\n",
    "        # a paper from 2001 did something that i liked better so i used that below, kept it anyway tho\n",
    "        def tsmallest_cluster_label(protein_id):\n",
    "            print(\"{} has {} neighbors\".format(protein_id, len(self.data_explorer.adj_list[protein_id])))\n",
    "        \n",
    "            tmp = [\n",
    "                self.data_explorer.annotation_list[nbor[0]]\n",
    "                for nbor in self.data_explorer.adj_list[protein_id]\n",
    "            ]\n",
    "\n",
    "            nbor_clusters = []\n",
    "\n",
    "            # need to identify this neighbor's cluster by membership to t^th-smallest cluster, parameterized\n",
    "            for cluster_list in tmp:\n",
    "                # (cluster, size) tuples, sort by size\n",
    "                zipped_list = [\n",
    "                    (cluster_id, self.data_explorer.cluster_sizes[cluster_id])\n",
    "                    for cluster_id in cluster_list\n",
    "                ]\n",
    "\n",
    "                sorted_list = sorted(zipped_list, key=lambda tup: tup[1])\n",
    "\n",
    "                # for each neighbor, we take the t^th smallest cluster that it's a part of, assign that to be\n",
    "                # its identity, then add this cluster to the neighbor cluster list from which we pick the majority\n",
    "                nbor_clusters.append(\n",
    "                    sorted_list[min(t - 1, len(sorted_list) - 1)][0]\n",
    "                )\n",
    "\n",
    "            most_common_nbor = Counter(nbor_clusters).most_common(1)[0][0]\n",
    "            \n",
    "            return most_common_nbor\n",
    "        \n",
    "        def expected_label_weight(protein_id, cluster_id):\n",
    "            # e(v, d, a) = expected number of nodes in a neighborhood of size n(v, d) with function a\n",
    "            # calculated as (# neighbors) * (# nodes labeled cluster_id / # nodes in network)\n",
    "            return len(self.data_explorer.adj_list[protein_id]) * (\n",
    "                self.data_explorer.cluster_sizes[cluster_id] / len(self.data_explorer.adj_list)\n",
    "            )\n",
    "        \n",
    "        def hishigaki_label(protein_id, n=15):\n",
    "            # want to maximize the function:\n",
    "            # |# labeled cluster_id - # expected labeled cluster_id| / # expected labeled cluster_id\n",
    "            # so we are taking the argmax of # labeled cluster_id over all function labels\n",
    "            label_score_dict = {}\n",
    "            \n",
    "#             tmp = []\n",
    "#             for (nbor, _) in self.data_explorer.adj_list[protein_id]:\n",
    "#                 tmp += self.data_explorer.annotation_list[nbor]\n",
    "#             cluster_counts = dict(Counter(tmp))\n",
    "            \n",
    "    \n",
    "    \n",
    "#             tmp = []\n",
    "#             for (nbor, score) in self.data_explorer.adj_list[protein_id]:\n",
    "#                 tmp += [(cluster, score) for cluster in self.data_explorer.annotation_list[nbor]]\n",
    "#             cluster_counts = {} \n",
    "#             for (cluster, score) in tmp:\n",
    "#                 if cluster not in cluster_counts:\n",
    "#                     cluster_counts[cluster] = (1 / score)\n",
    "#                 else:\n",
    "#                     cluster_counts[cluster] += (1 / score)\n",
    "    \n",
    "#             tmp = []\n",
    "#             cluster_scores = {}\n",
    "            \n",
    "#             for (nbor, score) in self.data_explorer.adj_list[protein_id]:\n",
    "#                 tmp += self.data_explorer.annotation_list[nbor]\n",
    "                \n",
    "#                 for cluster in self.data_explorer.annotation_list[nbor]:\n",
    "#                     if cluster not in cluster_scores:\n",
    "#                         cluster_scores[cluster] = score\n",
    "#                     else:\n",
    "#                         cluster_scores[cluster] += score\n",
    "            \n",
    "#             cluster_counts = dict(Counter(tmp))\n",
    "            \n",
    "            total_nbh, recent_nbh = self.get_nborhood(protein_id, r, df=\"list\")\n",
    "        \n",
    "            clusters = []\n",
    "            for nbor in total_nbh:\n",
    "                clusters += self.data_explorer.annotation_list[nbor]\n",
    "                \n",
    "            cluster_counts = dict(Counter(clusters))\n",
    "            \n",
    "            for cluster in self.data_explorer.cluster_sizes:\n",
    "                e = expected_label_weight(protein_id, cluster)\n",
    "\n",
    "                try:\n",
    "                    f = cluster_counts[cluster]\n",
    "                except KeyError:\n",
    "                    f = 0\n",
    "                \n",
    "                try:\n",
    "                    label_score_dict[cluster] = ((f - e ) ** 2) / e\n",
    "                except:\n",
    "                    label_score_dict[cluster] = 0\n",
    "                        \n",
    "            for cluster in label_score_dict:\n",
    "                if cluster not in cluster_counts:\n",
    "                    label_score_dict[cluster] = 0\n",
    "                else:\n",
    "                    label_score_dict[cluster] = label_score_dict[cluster] * \\\n",
    "                                                1 #(cluster_scores[cluster] / cluster_counts[cluster])\n",
    "            \n",
    "            zipped_dict = [(cluster, label_score_dict[cluster]) for cluster in label_score_dict]\n",
    "            zipped_dict_sorted = sorted(zipped_dict, key = lambda tup: tup[1])\n",
    "\n",
    "            \n",
    "            winners = ([tup[0] for tup in zipped_dict_sorted][::-1])[:int(len(zipped_dict_sorted) * 0.5)]\n",
    "            winners_scores = [label_score_dict[i] for i in winners]\n",
    "            \n",
    "            return winners\n",
    "        \n",
    "        cluster_assignments = {}\n",
    "        \n",
    "        for protein in protein_id_list:\n",
    "            cluster_assignments[protein] = hishigaki_label(protein)\n",
    "        \n",
    "        return cluster_assignments\n",
    "        \n",
    "        # return tsmallest_cluster_label()\n",
    "    \n",
    "    def functional_flow(self, protein_id_list, t=2):\n",
    "        def expected_label_weight(protein_id, cluster_id):\n",
    "            # e(v, d, a) = expected number of nodes in a neighborhood of size n(v, d) with function a\n",
    "            # calculated as (# neighbors) * (# nodes labeled cluster_id / # nodes in network)\n",
    "            return len(self.data_explorer.adj_list[protein_id]) * (\n",
    "                self.data_explorer.cluster_sizes[cluster_id] / len(self.data_explorer.adj_list)\n",
    "            )\n",
    "        \n",
    "        \"\"\"def expected_flow(cluster):\n",
    "            # known: number of nodes in this cluster, number of nodes in the network\n",
    "            # calculate the expected flow of function A into a given node over t iterations\n",
    "            # expected value of flow amount is sum over all \n",
    "            # known: average degree of a node\n",
    "            # for a random node, P(neighbor has function A) = ((# function A) / (# total)) * # neighbors\n",
    "            # P(n within radius R has function A) = \n",
    "            # (score / max_score) * (# neighbors)\n",
    "            for i in range(1, t+1):\n",
    "                flow = avg_degree * \"\"\"\n",
    "        \n",
    "        def get_nborhood_helper(protein, r):\n",
    "            # want to get r-neighborhood of protein\n",
    "            if r == 0: return set([protein])\n",
    "            \n",
    "            last_nborhood = get_nborhood_helper(protein, r - 1)\n",
    "            fnl_nborhood = []\n",
    "            \n",
    "            for protein in last_nborhood:\n",
    "                for (nbor, score) in self.data_explorer.adj_list[protein]:\n",
    "                    fnl_nborhood.append(nbor)\n",
    "            return set(fnl_nborhood)\n",
    "        \n",
    "        def get_nborhood():\n",
    "            nborhood = []\n",
    "            for protein in protein_id_list:\n",
    "                nborhood += list(get_nborhood_helper(protein, t))\n",
    "            return nborhood\n",
    "        \n",
    "        \n",
    "        working_nborhood = get_nborhood()\n",
    "        print(\"WORKING NBORHOOD SIZE:\", len(working_nborhood))\n",
    "        \n",
    "        # input: protein_id, adjacency list graph representation\n",
    "        # output: cluster_id of protein_id based on the majority rule of protein_id's neighbors\n",
    "        \n",
    "        # idea from Nabieva et al paper\n",
    "        # Whole-proteome prediction of protein function via graph-theoretic analysis of interaction maps\n",
    "        \n",
    "        # we start by picking some list of proteins that we want to know the function of\n",
    "        # we also start with some known protein functions of nodes in the network\n",
    "        # we fill the known nodes with infinite water at t=0\n",
    "        # for t timesteps, we simulate the flow of water out of the known nodes, along edges, to proteins of\n",
    "        # unknown function, and at t=t, we look at how much water has reached unknown nodes\n",
    "        # (the flow volume between nodes is determined by edge weight)\n",
    "        \n",
    "        resoviors = {0: {}} # fill the nodes at t=0 according to known function or not\n",
    "        # resoviors keep track of resoviors at each timestep\n",
    "        # at a given timestep i, for each node u, we track the amount in the resovior for function a that u has\n",
    "        \n",
    "        print(\"INIT RESOVIORS\")\n",
    "        for protein in self.data_explorer.adj_list:\n",
    "            if protein not in protein_id_list:\n",
    "                function_dict = {}\n",
    "                for cluster in self.data_explorer.cluster_sizes:\n",
    "                    if cluster in self.data_explorer.annotation_list[protein]:\n",
    "                        function_dict[cluster] = 2 ** 100\n",
    "                    else:\n",
    "                        function_dict[cluster] = 0.0\n",
    "                \n",
    "                resoviors[0][protein] = function_dict\n",
    "            else:\n",
    "                function_dict = {}\n",
    "                for cluster in self.data_explorer.cluster_sizes:\n",
    "                    function_dict[cluster] = 0.0\n",
    "                \n",
    "                resoviors[0][protein] = function_dict\n",
    "        \n",
    "        # pprint.pprint(resoviors[0][\"362663.ECP_1662\"])\n",
    "                \n",
    "        def edge_capacity(u, v, a, t):\n",
    "            cluster_size = self.data_explorer.cluster_sizes[a]\n",
    "            \n",
    "            if t == 0: return 0\n",
    "            if resoviors[t - 1][u][a] <= resoviors[t - 1][v][a]:\n",
    "                return 0\n",
    "            else:\n",
    "                uv_weight = 0\n",
    "                for (protein, score) in self.data_explorer.adj_list[u]:\n",
    "                    if protein == v:\n",
    "                        uv_weight = score\n",
    "                \n",
    "                u_weights = sum([score for (_, score) in self.data_explorer.adj_list[u]])\n",
    "                \n",
    "                return min(\n",
    "                    uv_weight,\n",
    "                    (uv_weight / u_weights)\n",
    "                ) / cluster_size\n",
    "        # print(edge_capacity(\"362663.ECP_1662\", \"362663.ECP_2098\", \"8452\", 1))\n",
    "       \n",
    "        # build the resoviors\n",
    "        label_score_dict = {}\n",
    "        for protein in protein_id_list:\n",
    "            label_score_dict[protein] = {}\n",
    "            for cluster in self.data_explorer.cluster_sizes:\n",
    "                label_score_dict[protein][cluster] = 0.0\n",
    "        \n",
    "        print(\"----- FF SIMULATION -----\")\n",
    "        for i in range(1, t + 1):\n",
    "            print(\"ITER: {} / {}\".format(i, t))\n",
    "            resovior_i = copy.deepcopy(resoviors[i - 1])\n",
    "            for protein in working_nborhood:\n",
    "                for cluster in self.data_explorer.cluster_sizes:\n",
    "                    test_val = sum(\n",
    "                        [ edge_capacity(nbor, protein, cluster, i) - edge_capacity(protein, nbor, cluster, i)\n",
    "                          for (nbor, score) in self.data_explorer.adj_list[protein] ]\n",
    "                    )\n",
    "                    resovior_i[protein][cluster] = resoviors[i - 1][protein][cluster] + test_val\n",
    "                    \n",
    "            resoviors[i] = resovior_i\n",
    "            \n",
    "            for protein in protein_id_list:\n",
    "                for cluster in self.data_explorer.cluster_sizes:\n",
    "                    for (nbor, score) in self.data_explorer.adj_list[protein]:\n",
    "                        label_score_dict[protein][cluster] += edge_capacity(nbor, protein, cluster, i)\n",
    "        \n",
    "        cluster_assignments = {}\n",
    "        \n",
    "        for protein in protein_id_list:\n",
    "            cluster_assignments[protein] = {}\n",
    "            for cluster in label_score_dict[protein]:\n",
    "                if label_score_dict[protein][cluster] > 0: # add all non-zero flow scores\n",
    "                    cluster_assignments[protein][cluster] = label_score_dict[protein][cluster]\n",
    "        \n",
    "#         pprint.pprint(resoviors)\n",
    "        \n",
    "        # calculate functional score\n",
    "#         label_score_dict = {}\n",
    "#         for i in range(1, t + 1):\n",
    "#             print(\"FSCORES: t\", i)\n",
    "#             for protein in protein_id_list:\n",
    "#                 label_score_dict[protein] = {}\n",
    "#                 for cluster in self.data_explorer.cluster_sizes:\n",
    "#                     if cluster not in label_score_dict[protein]:\n",
    "#                         label_score_dict[protein][cluster] = 0\n",
    "#                     for (nbor, score) in self.data_explorer.adj_list[protein]:\n",
    "#                         label_score_dict[protein][cluster] += edge_capacity(nbor, protein, cluster, i)\n",
    "        \n",
    "        # pprint.pprint(label_score_dict)\n",
    "        return cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bba202e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING NBORHOOD SIZE: 41\n",
      "INIT RESOVIORS\n",
      "----- FF SIMULATION -----\n",
      "ITER: 1 / 2\n",
      "ITER: 2 / 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'362663.ECP_1200': {'0': 0.00039376268447855524,\n",
       "  '1049': 0.0005905765814052743,\n",
       "  '1050': 0.0006326105017899913,\n",
       "  '12': 0.00039530954792696513,\n",
       "  '1466': 0.002435117137027227,\n",
       "  '1467': 0.0035552710200597516,\n",
       "  '1468': 0.006348698250106699,\n",
       "  '1469': 0.008080161409226709,\n",
       "  '1470': 0.011110221937686723,\n",
       "  '16': 0.000395741391435734,\n",
       "  '21': 0.0003961741794841107,\n",
       "  '23': 0.0003966079151743714,\n",
       "  '244': 0.0030287079084238156,\n",
       "  '247': 0.004097663640808692,\n",
       "  '248': 0.006966028189374776,\n",
       "  '253': 0.013932056378749553,\n",
       "  '27': 0.00039704260162239243,\n",
       "  '29': 0.000402960700467487,\n",
       "  '30': 0.0004040393371852229,\n",
       "  '32': 0.00040449047534643916,\n",
       "  '33': 0.0004050331727641669,\n",
       "  '34': 0.00040557732839260056,\n",
       "  '35': 0.0004074017878095713,\n",
       "  '36': 0.0004083201867902061,\n",
       "  '37': 0.0004120355661058585,\n",
       "  '38': 0.0004125047480303699,\n",
       "  '39': 0.00041648846829187263,\n",
       "  '40': 6.954014415310155e-05,\n",
       "  '41': 6.979515737566582e-05,\n",
       "  '42': 6.999259770770447e-05,\n",
       "  '43': 7.144782930890423e-05,\n",
       "  '44': 7.561853083641055e-05,\n",
       "  '45': 7.627121852550412e-05,\n",
       "  '46': 8.849207185147901e-05,\n",
       "  '47': 0.00010614493045762991,\n",
       "  '48': 0.00010697096104484883,\n",
       "  '49': 0.00011386278550240927,\n",
       "  '50': 0.00011621598539066949,\n",
       "  '51': 0.00011704060212712174,\n",
       "  '52': 0.0001181584684320608,\n",
       "  '53': 0.00018715872382506457,\n",
       "  '54': 0.00019209924914342805,\n",
       "  '55': 0.00019451559189994917,\n",
       "  '56': 0.00020247449500551172,\n",
       "  '57': 0.0002461928685539655,\n",
       "  '58': 0.0002590825475358485,\n",
       "  '59': 0.0002827700947391261,\n",
       "  '60': 0.0002893845998792226,\n",
       "  '61': 0.00029560792460780805,\n",
       "  '62': 0.00030210480207171594,\n",
       "  '63': 0.0003116169180059639,\n",
       "  '64': 0.00014129874623478248,\n",
       "  '65': 0.00018046705153820664,\n",
       "  '66': 0.0001828353855478944,\n",
       "  '68': 0.00018929424427648848,\n",
       "  '69': 0.00019678045732697108,\n",
       "  '70': 0.0002710516805204193,\n",
       "  '71': 0.000279760168247983,\n",
       "  '7155': 0.0019770979970981273,\n",
       "  '7156': 0.00206589764293873,\n",
       "  '72': 0.00030155966187769595,\n",
       "  '73': 0.000322501305063647,\n",
       "  '74': 0.00038916358599859084,\n",
       "  '75': 0.00041712743648950756,\n",
       "  '76': 0.0005122079551010865,\n",
       "  '78': 0.0005485061566436832,\n",
       "  '79': 0.0005853805201155274,\n",
       "  '8': 0.0003948786458690547,\n",
       "  '80': 0.000663431256130931,\n",
       "  '8600': 0.04468241473441768,\n",
       "  '8639': 0.13032370964205156,\n",
       "  '8642': 0.2606474192841031}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptr = [\"362663.ECP_1200\"]\n",
    "f = FunctionPrediction(\"ecoli\")\n",
    "# f.majority_rule(ptr)\n",
    "# pprint.pprint(f.data_explorer.adj_list)\n",
    "\n",
    "# print(f.majority_rule(ptr))\n",
    "# print(f.data_explorer.annotation_list[ptr[0]])\n",
    "# print(f.data_explorer.adj_list[ptr[0]])\n",
    "f.functional_flow(ptr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
