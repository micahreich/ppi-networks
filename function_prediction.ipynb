{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e62c03ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/testenv/lib/python3.8/site-packages/Bio/SubsMat/__init__.py:126: BiopythonDeprecationWarning: Bio.SubsMat has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.substitution_matrices as a replacement, and contact the Biopython developers if you still need the Bio.SubsMat module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import copy\n",
    "from ipynb.fs.full.data_explore import DataExplorer\n",
    "from collections import Counter\n",
    "import pprint\n",
    "from Bio import pairwise2\n",
    "from Bio.SubsMat import MatrixInfo as matlist\n",
    "import operator\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19a875de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintColors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    \n",
    "    APPROACH_TITLE = BOLD + OKBLUE\n",
    "    NBORHOOD_SIZE = WARNING\n",
    "    \n",
    "    @classmethod\n",
    "    def print(self, msg, msgn=\"\", color=None):\n",
    "        if not color:\n",
    "            color = PrintColors.BOLD\n",
    "            \n",
    "        print(f\"{color}{msg}{PrintColors.ENDC} {msgn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b45aae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionPrediction():\n",
    "    def __init__(self, organism_name):\n",
    "        # get all the annotation, adjacency list data from the explorer class\n",
    "        self.data_explorer = DataExplorer(organism_name)\n",
    "    \n",
    "    # used to get r-neighborhood of protein\n",
    "    def get_nborhood(self, protein, r, df=\"set\"):\n",
    "        if r == 1:\n",
    "            fnl_nborhood = [\n",
    "                nbor for (nbor, score) in self.data_explorer.adj_list[protein]\n",
    "            ]\n",
    "\n",
    "            if df == \"set\":\n",
    "                return set(fnl_nborhood), set(fnl_nborhood)\n",
    "            else:\n",
    "                return fnl_nborhood, fnl_nborhood\n",
    "\n",
    "        accum, last_nborhood = self.get_nborhood(protein, r - 1, df)\n",
    "\n",
    "        fnl_nborhood = []\n",
    "\n",
    "        for protein in last_nborhood:\n",
    "            for (nbor, score) in self.data_explorer.adj_list[protein]:\n",
    "                fnl_nborhood.append(nbor)\n",
    "\n",
    "        if df == \"set\":\n",
    "            return set.union(set(accum), set(fnl_nborhood)), set(fnl_nborhood)\n",
    "        else:\n",
    "            return accum + fnl_nborhood, fnl_nborhood\n",
    "    \n",
    "    # majority approach function predictor\n",
    "    def majority_rule(self, protein_id_list, r=1):\n",
    "        # input\n",
    "            # protein_id_list : List = list of unknown proteins whose functions we predict\n",
    "            # r : int = radius neighborhood to consider\n",
    "        # output\n",
    "            # cluster_assignments : Dict = dictionary of (protein_id, function list) key-value pairs\n",
    "            \n",
    "        PrintColors.print(\"MAJORITY APPROACH\", color=PrintColors.APPROACH_TITLE)\n",
    "        \n",
    "        def expected_label_weight(cluster_id, n):\n",
    "            # calculate the expected value of # of proteins with cluster `cluster_id` in a group of size `n`\n",
    "                # E(# of proteins with `cluster_id` | size = n) = P(protein has `cluster_id`) * (size)\n",
    "                #                                               = (# with `cluster_id` / # total) * (size)\n",
    "            return (self.data_explorer.cluster_sizes[cluster_id] / len(self.data_explorer.adj_list)) * n\n",
    "        \n",
    "        def hishigaki_label(protein_id, n=15):\n",
    "            cluster_score_dict = {} # dict to keep track of a cluster's score\n",
    "            \n",
    "            # get the neighborhood of this current protein\n",
    "            total_nbh, recent_nbh = self.get_nborhood(protein_id, r, df=\"set\")\n",
    "            nborhood_size = len(total_nbh)\n",
    "            \n",
    "            PrintColors.print(\"WORKING NBORHOOD SIZE:\", f\"{len(nborhood_size)} ({protein_id})\", color=PrintColors.NBORHOOD_SIZE)\n",
    "\n",
    "            \n",
    "            # find all clusters present within nborhood\n",
    "            clusters = [] \n",
    "            \n",
    "            for nbor in total_nbh:\n",
    "                if nbor not in protein_id_list: # only add clusters of a neighbor if neighbor is a \"known\" protein\n",
    "                    clusters += self.data_explorer.annotation_list[nbor]\n",
    "                \n",
    "            cluster_counts = dict(Counter(clusters)) # count how many times a cluster appears in the neighborhood\n",
    "            \n",
    "            for cluster in clusters:\n",
    "                expected_frequency = expected_label_weight(cluster, nborhood_size)\n",
    "                observed_frequency = cluster_counts[cluster]\n",
    "                \n",
    "                # calculate scoring metric\n",
    "                cluster_score = (observed_frequency - expected_frequency) / expected_frequency\n",
    "                cluster_score_dict[cluster] = cluster_score\n",
    "            \n",
    "            # sort the scored clusters in increasing order\n",
    "            zipped_dict = [(cluster, cluster_score_dict[cluster]) for cluster in cluster_score_dict]\n",
    "            zipped_dict_sorted = sorted(zipped_dict, key = lambda tup: tup[1])\n",
    "            \n",
    "            # determine the winners by reversing the sorted cluster list, so the winners have the highest metric\n",
    "            winners = ([cluster for (cluster, score) in zipped_dict_sorted][::-1])\n",
    "            winners_scores = [label_score_dict[i] for i in winners]\n",
    "            \n",
    "            return winners\n",
    "        \n",
    "        cluster_assignments = {}\n",
    "        \n",
    "        for protein in protein_id_list:\n",
    "            cluster_assignments[protein] = hishigaki_label(protein)\n",
    "        \n",
    "        return cluster_assignments\n",
    "            \n",
    "    # functional flow function predictor\n",
    "    def functional_flow(self, protein_id_list, t=2):\n",
    "        # input\n",
    "            # protein_id_list : List = list of unknown proteins whose functions we predict\n",
    "            # t : int = # of iterations to run flow sim for\n",
    "        # output\n",
    "            # cluster_assignments : Dict = dictionary of (protein_id, function list) key-value pairs\n",
    "            \n",
    "        PrintColors.print(\"FLOW APPROACH\", color=PrintColors.APPROACH_TITLE)\n",
    "    \n",
    "        working_nborhood = set([])\n",
    "        for protein_id in protein_id_list:\n",
    "            total_nbh, recent_nbh = self.get_nborhood(protein_id, t, df=\"set\")\n",
    "            working_nborhood.update(total_nbh)\n",
    "        \n",
    "        PrintColors.print(\"WORKING NBORHOOD SIZE:\", f\"{len(working_nborhood)} ({protein_id})\", color=PrintColors.NBORHOOD_SIZE)\n",
    "\n",
    "        observed_clusters = set() # all clusters observed in the neighborhood\n",
    "        \n",
    "        for protein in working_nborhood:\n",
    "            observed_clusters.update(set(self.data_explorer.annotation_list[protein]))\n",
    "        \n",
    "        # we start by picking some list of proteins that we want to know the function of\n",
    "        # we also start with some known protein functions of nodes in the network\n",
    "        # we fill the known nodes with infinite water at t=0\n",
    "        # for t timesteps, we simulate the flow of water out of the known nodes, along edges, to proteins of\n",
    "        # unknown function, and at t=t, we look at how much water has reached unknown nodes\n",
    "        # (the flow volume between nodes is determined by edge weight)\n",
    "        \n",
    "        resoviors = {0: {}} # fill the nodes at t = 0 according to known function or not\n",
    "        \n",
    "        # resoviors dict keeps track of resoviors at each timestep\n",
    "        # at a given timestep i, for each node u, we track the amount in the resovior for function a that u has\n",
    "        \n",
    "        for protein in self.data_explorer.adj_list:\n",
    "            if protein not in protein_id_list:\n",
    "                function_dict = {}\n",
    "                \n",
    "                for cluster in self.data_explorer.cluster_sizes:\n",
    "                    if cluster in self.data_explorer.annotation_list[protein]:\n",
    "                        function_dict[cluster] = 2 ** 100\n",
    "                    else:\n",
    "                        function_dict[cluster] = 0.0\n",
    "                \n",
    "                resoviors[0][protein] = function_dict\n",
    "            else:\n",
    "                function_dict = {}\n",
    "                for cluster in self.data_explorer.cluster_sizes:\n",
    "                    function_dict[cluster] = 0.0\n",
    "                \n",
    "                resoviors[0][protein] = function_dict\n",
    "                        \n",
    "        def edge_capacity(u, v, a, t):\n",
    "            cluster_size = self.data_explorer.cluster_sizes[a]\n",
    "            \n",
    "            if t == 0: return 0\n",
    "            if resoviors[t - 1][u][a] <= resoviors[t - 1][v][a]:\n",
    "                return 0\n",
    "            else:\n",
    "                uv_weight = 0\n",
    "                \n",
    "                for (protein, score) in self.data_explorer.adj_list[u]:\n",
    "                    if protein == v:\n",
    "                        uv_weight = score\n",
    "                \n",
    "                u_weights = sum([score for (_, score) in self.data_explorer.adj_list[u]])\n",
    "                \n",
    "                return min(\n",
    "                    uv_weight,\n",
    "                    (uv_weight / u_weights)\n",
    "                ) \n",
    "       \n",
    "        # initialize the label scoring dictionary\n",
    "        label_score_dict = {}\n",
    "        \n",
    "        for protein in protein_id_list:\n",
    "            label_score_dict[protein] = {}\n",
    "            \n",
    "            for cluster in self.data_explorer.cluster_sizes:\n",
    "                label_score_dict[protein][cluster] = 0.0\n",
    "        \n",
    "        # build the resoviors\n",
    "        for i in range(1, t + 1):\n",
    "            resovior_i = copy.deepcopy(resoviors[i - 1])\n",
    "            \n",
    "            for protein in working_nborhood:\n",
    "                for cluster in observed_clusters:\n",
    "                    amt_entered = sum([\n",
    "                        edge_capacity(nbor, protein, cluster, i) for (nbor, _) in self.data_explorer.adj_list[protein]\n",
    "                    ])\n",
    "                    \n",
    "                    amt_left = sum([\n",
    "                        edge_capacity(protein, nbor, cluster, i) for (nbor, _) in self.data_explorer.adj_list[protein]\n",
    "                    ])\n",
    "                    \n",
    "                    resovior_i[protein][cluster] = resoviors[i - 1][protein][cluster] + (amt_entered - amt_left)\n",
    "                    \n",
    "                    label_score_dict[protein][cluster] += amt_entered # add the amount entered to the label scoring\n",
    "                    \n",
    "            resoviors[i] = resovior_i\n",
    "            \n",
    "        # determine winning clusters for unknown proteins\n",
    "        cluster_assignments_dict = {}\n",
    "        \n",
    "        for protein in protein_id_list:\n",
    "            cluster_assignments_dict[protein] = [\n",
    "                (cluster, label_score_dict[protein][cluster]) for cluster in label_score_dict[protein]\n",
    "            ]\n",
    "        \n",
    "        cluster_assignments = {}\n",
    "        \n",
    "        for protein in cluster_assignments_dict:\n",
    "            score_list = cluster_assignments_dict[protein]\n",
    "            sorted_score_list = [cluster for (cluster, score) in sorted(score_list, key = lambda tup: tup[1])]\n",
    "            \n",
    "            cluster_assignments[protein] = sorted_score_list[::-1]\n",
    "        \n",
    "        # determine the winners by reversing the sorted cluster list, so the winners have the highest metric\n",
    "        return cluster_assignments\n",
    "    \n",
    "    def alignment_approach(self, protein_id_list, r=1):\n",
    "        # input\n",
    "            # protein_id_list : List = list of unknown proteins whose functions we predict\n",
    "            # r : int = radius neighborhood to consider\n",
    "        # output\n",
    "            # cluster_assignments : Dict = dictionary of (protein_id, function list) key-value pairs\n",
    "            \n",
    "        PrintColors.print(\"ALIGNMENT APPROACH\", color=PrintColors.APPROACH_TITLE)\n",
    "        \n",
    "        # use BLOSUM62 for match/mismatch penalties and a -2 gap open, -1 gap extend penalty for use in\n",
    "        # affine global alignment of amino acid strings\n",
    "        scoring_matrix = matlist.blosum62\n",
    "        \n",
    "        def single_alignment(protein_id, r=r):\n",
    "            if protein_id not in self.data_explorer.sequences:\n",
    "                return []\n",
    "            \n",
    "            total_nbh, recent_nbh = self.get_nborhood(protein_id, r, df=\"set\")\n",
    "            score_list = {}\n",
    "            \n",
    "            PrintColors.print(\"WORKING NBORHOOD SIZE:\", f\"{len(total_nbh)} ({protein_id})\", color=PrintColors.NBORHOOD_SIZE)\n",
    "\n",
    "            # perform global alignment of all neighbors against alignment of protein and assign it\n",
    "            # the functions of whichever protein score best against it\n",
    "            for nbor in recent_nbh:\n",
    "                if nbor not in protein_id_list:\n",
    "                    try:\n",
    "                        alignments = pairwise2.align.globalds(self.data_explorer.sequences[protein_id], \n",
    "                                                              self.data_explorer.sequences[nbor], \n",
    "                                                              scoring_matrix,\n",
    "                                                              -2, -1\n",
    "                                                             )\n",
    "                        score_list[nbor] = max([algn.score for algn in alignments])\n",
    "                    except KeyError:\n",
    "                        # couldnt find nbor sequence\n",
    "                        pass\n",
    "                    \n",
    "            winner = max(score_list.items(), key=operator.itemgetter(1))[0]\n",
    "            return self.data_explorer.annotation_list[winner]\n",
    "        \n",
    "        cluster_assignments = {}\n",
    "        \n",
    "        for protein in protein_id_list:\n",
    "            cluster_assignments[protein] = single_alignment(protein)\n",
    "        \n",
    "        return cluster_assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421cdbf0",
   "metadata": {},
   "source": [
    "### Usage of ``FunctionPrediction`` class\n",
    "To create a new instance of the class, create a new variable with the organism name (same as organism name used to instantiate the DataExplorer class; will be the name of the folder which contains the PPI info):\n",
    "```\n",
    "function_predictor = FunctionPrediction(\"organism_name\")\n",
    "```\n",
    "\n",
    "To perform the majority approach with a radius `r` and list of proteins to predict `p`, run the function:\n",
    "```\n",
    "majority_approach_results = function_predictor.majority_rule(p, r=r)\n",
    "```\n",
    "\n",
    "To perform functional flow for `t` iterations and list of proteins to predict `p`, run the function:\n",
    "```\n",
    "functional_flow_results = function_predictor.functional_flow(p, t=t)\n",
    "```\n",
    "To perform sequence alignment approach with a radius `r` and list of proteins to predict `p`, run the function:\n",
    "```\n",
    "alignment_approach_results = function_predictor.alignment_approach(p, r=r)\n",
    "```\n",
    "\n",
    "In all methods, the function returns a dictionary of the form:\n",
    "```\n",
    "{protein_id: [list of functions (by name) scored and sorted in descending order]}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
