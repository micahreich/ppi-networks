{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eaa999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import json\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import statistics\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "from ipynb.fs.full.data_explore import DataExplorer\n",
    "from ipynb.fs.full.function_prediction import FunctionPrediction\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba2df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RawResults class holds all info \n",
    "class RawResults():\n",
    "    def __init__(self, organism_name, n, r, do_alignment=True):\n",
    "        \n",
    "        # folder name\n",
    "        self.organism_name = organism_name\n",
    "        # length of list of proteins\n",
    "        self.n = n\n",
    "        # radius or timestep\n",
    "        self.r = r\n",
    "        \n",
    "        # adjustable variables for raw scoring that we currently do not use\n",
    "        self.true_positive_reward = 1\n",
    "        self.false_positive_penalty = -0.25\n",
    "        self.false_negative_penalty = -0.25\n",
    "        \n",
    "        # DataExplorer\n",
    "        self.data_explorer = DataExplorer(self.organism_name)\n",
    "        # used to get the actual list of annotations for a protein: self.annotation_dict[self.p[p]]\n",
    "        self.annotation_dict = self.data_explorer.annotation_list\n",
    "        # used in get_test_proteins() to gather self.p\n",
    "        self.names_set = self.data_explorer.filtered_names_set\n",
    "        self.names_list = self.data_explorer.filtered_names_list\n",
    "        # used in get_global/local_percentile_ to get list of glosters sorted by size\n",
    "        self.global_clusters_sorted = self.data_explorer.clusters_sorted\n",
    "        \n",
    "        # gathering list of test proteins\n",
    "        self.p = self.get_test_proteins(n)\n",
    "        print(self.p)\n",
    "        # FunctionPrediction\n",
    "        function_predictor = FunctionPrediction(self.organism_name)\n",
    "        # raw results \n",
    "        self.majority_approach_results = function_predictor.majority_rule(self.p, r=self.r)\n",
    "        self.functional_flow_results = function_predictor.functional_flow(self.p, t=self.r)\n",
    "        \n",
    "        if do_alignment:\n",
    "            self.alignment_approach_results = function_predictor.alignment_approach(self.p, r=self.r)\n",
    "\n",
    "    # returns a random size n list of proteins to test\n",
    "    def get_test_proteins(self, n):\n",
    "        kz = self.data_explorer.adj_list.keys()\n",
    "        return random.sample(kz, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8322dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compares results from FunctionPrediction to actual\n",
    "def compare(p, annotation, results):\n",
    "    true_positive = []\n",
    "    false_positive = []\n",
    "    false_negative = []\n",
    "    for i in range(len(p)):\n",
    "        protein = p[i]\n",
    "        true_positive.append([set(), 0])\n",
    "        false_positive.append([set(), 0])\n",
    "        false_negative.append([set(), 0])\n",
    "        actual_clusters = copy.deepcopy(annotation[protein])\n",
    "        result_clusters = results[protein]\n",
    "        if len(result_clusters) >= len(actual_clusters):\n",
    "            for j in range(len(actual_clusters)):\n",
    "                cluster = result_clusters[j]\n",
    "                if cluster in actual_clusters:\n",
    "                    true_positive[i][0].add(cluster)\n",
    "                    true_positive[i][1] += 1\n",
    "                    actual_clusters.remove(cluster)\n",
    "                elif cluster not in actual_clusters:\n",
    "                    false_positive[i][0].add(cluster)\n",
    "                    false_positive[i][1] += 1\n",
    "            for cluster in actual_clusters:\n",
    "                false_negative[i][0].add(cluster)\n",
    "                false_negative[i][1] += 1\n",
    "        elif len(result_clusters) < len(actual_clusters):\n",
    "            for j in range(len(result_clusters)):\n",
    "                cluster = actual_clusters[j]\n",
    "                if cluster in result_clusters:\n",
    "                    true_positive[i][0].add(cluster)\n",
    "                    true_positive[i][1] += 1\n",
    "                    result_clusters.remove(cluster)\n",
    "                elif cluster not in result_clusters:\n",
    "                    false_negative[i][0].add(cluster)\n",
    "                    false_negative[i][1] += 1\n",
    "            for cluster in result_clusters:\n",
    "                false_positive[i][0].add(cluster)\n",
    "                false_positive[i][1] += 1\n",
    "    return true_positive, false_positive, false_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds where actual protein clusters fall in the global cluster size distribution\n",
    "def get_global_percentile_actual(p, true_positive, annotation_dict, global_clusters_sorted):\n",
    "    percentile = []\n",
    "    for protein in range(len(p)):\n",
    "        for c in annotation_dict[p[protein]]:\n",
    "            i = global_clusters_sorted.index(c)\n",
    "            percentile.append((i/len(global_clusters_sorted)*100)//1)\n",
    "    listof100actual = []\n",
    "    totallen = 0\n",
    "    for protein in range(len(p)):\n",
    "        totallen = len(annotation_dict[p[protein]])\n",
    "    for i in range(100):\n",
    "        listof100actual.append((percentile.count(i)/totallen*100)//(len(p)))\n",
    "    return listof100actual\n",
    "\n",
    "# finds where true positive predictions of protein clusters fall in the global cluster size distribution\n",
    "def get_global_percentile(p, true_positive, annotation_dict, global_clusters_sorted):\n",
    "    percentile = []\n",
    "    for protein in range(len(p)):\n",
    "        for c in annotation_dict[p[protein]]:\n",
    "            i = global_clusters_sorted.index(c)\n",
    "            percentile.append((i/len(global_clusters_sorted)*100)//1)\n",
    "    listof100actual = []\n",
    "    totallen = 0\n",
    "    for protein in range(len(p)):\n",
    "        totallen = len(annotation_dict[p[protein]])\n",
    "    for i in range(100):\n",
    "        listof100actual.append((percentile.count(i)))\n",
    "    listof100avg = []\n",
    "    for i in range(100):\n",
    "        listof100avg.append([])\n",
    "    percentile = []\n",
    "    for protein in range(len(p)):\n",
    "        for tp in true_positive[protein][0]:\n",
    "            i = global_clusters_sorted.index(tp)\n",
    "            percentile.append((i/len(global_clusters_sorted)*100)//1)\n",
    "        listof100result = []\n",
    "        for i in range(100):\n",
    "            listof100result.append(percentile.count(i))\n",
    "        for i in range(100):\n",
    "            listof100avg[i].append(listof100result[i])\n",
    "    for i in range(100):\n",
    "        totalfori = 0\n",
    "        for j in range(len(listof100avg[i])):\n",
    "            totalfori += listof100avg[i][j]\n",
    "        totalfori/=len(listof100avg[i])\n",
    "        listof100avg[i] = totalfori\n",
    "    listof100 = []\n",
    "    for i in range(100):\n",
    "        if listof100actual[i] == 0:\n",
    "            listof100.append(0)\n",
    "        else:\n",
    "            listof100.append(((listof100avg[i]/listof100actual[i])*100)//1)\n",
    "    return listof100\n",
    "        \n",
    "# finds where actual protein clusters fall in the local cluster size distribution\n",
    "def get_local_percentile(p, true_positive, annotation_dict, global_clusters_sorted):\n",
    "    clusters = []\n",
    "    cluster_len_total = 0\n",
    "    for protein in range(len(p)):\n",
    "        cluster_unsorted = annotation_dict[p[protein]]\n",
    "        cluster_sorted = []\n",
    "        for c in global_clusters_sorted:\n",
    "            if c in cluster_unsorted:\n",
    "                cluster_sorted.append(c)\n",
    "        clusters.append(cluster_sorted)\n",
    "        cluster_len_total += len(cluster_sorted)\n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append(0)\n",
    "    for i in range(len(p)):\n",
    "        tpi = true_positive[i]\n",
    "        ci = clusters[i]\n",
    "        for tp in tpi[0]:\n",
    "            percentile[int((ci.index(tp)/len(ci)*100)//1)]+=1\n",
    "    for i in range(100):\n",
    "        if percentile[i] != 0:\n",
    "            percentile[i] == (percentile[i]/(cluster_len_total/100)*100*100)\n",
    "    return percentile        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2dd27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorityApproachResults():\n",
    "    def __init__(self, raw_results):\n",
    "        self.global_title = 'Global Specificity with Majority Approach'\n",
    "        self.global_color = '#ff7979'\n",
    "        self.local_title = 'Local Specificity with Majority Approach'\n",
    "        self.local_color = '#eb4d4b'\n",
    "        \n",
    "        # info gathered from raw_results\n",
    "        self.p = raw_results.p\n",
    "        self.annotation_dict = raw_results.annotation_dict\n",
    "        self.global_clusters_sorted = raw_results.global_clusters_sorted\n",
    "        self.raw_results = raw_results.majority_approach_results\n",
    "        \n",
    "        # 2D lists of length self.n corresponding to the proteins in self.p: [[{cluster_ids},count]]\n",
    "        self.true_positive, self.false_positive, self.false_negative = (\n",
    "            compare(self.p, self.annotation_dict, self.raw_results))\n",
    "        \n",
    "        self.global_percentile_actual = get_global_percentile_actual(self.p, self.true_positive, self.annotation_dict,\n",
    "                                                                     self.global_clusters_sorted)\n",
    "        self.global_percentile = get_global_percentile(self.p, self.true_positive, self.annotation_dict, \n",
    "                                                       self.global_clusters_sorted)\n",
    "        self.local_percentile = get_local_percentile(self.p, self.true_positive, self.annotation_dict, \n",
    "                                                     self.global_clusters_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21610f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionalFlowResults():\n",
    "    def __init__(self, raw_results):\n",
    "        self.global_title = 'Global Specificity with Functional Flow'\n",
    "        self.global_color = '#7ed6df'\n",
    "        self.local_title = 'Local Specificity with Functional Flow'\n",
    "        self.local_color = '#22a6b3'\n",
    "        \n",
    "        # info gathered from raw_results\n",
    "        self.p = raw_results.p\n",
    "        self.annotation_dict = raw_results.annotation_dict\n",
    "        self.global_clusters_sorted = raw_results.global_clusters_sorted\n",
    "        self.raw_results = raw_results.functional_flow_results\n",
    "        \n",
    "        # 2D lists of length self.n corresponding to the proteins in self.p: [[{cluster_ids},count]]\n",
    "        self.true_positive, self.false_positive, self.false_negative = (\n",
    "            compare(self.p, self.annotation_dict, self.raw_results))\n",
    "        \n",
    "        self.global_percentile_actual = get_global_percentile_actual(self.p, self.true_positive, self.annotation_dict,\n",
    "                                                                     self.global_clusters_sorted)\n",
    "        self.global_percentile = get_global_percentile(self.p, self.true_positive, self.annotation_dict, \n",
    "                                                       self.global_clusters_sorted)\n",
    "        self.local_percentile = get_local_percentile(self.p, self.true_positive, self.annotation_dict, \n",
    "                                                     self.global_clusters_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e56e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignmentApproachResults():\n",
    "    def __init__(self, raw_results):\n",
    "        self.global_title = 'Global Specificity with Alignment Approach'\n",
    "        self.global_color = '#badc58'\n",
    "        self.local_title = 'Local Specificity with Alignment Approach'\n",
    "        self.local_color = '#6ab04c'\n",
    "        \n",
    "        # info gathered from raw_results\n",
    "        self.p = raw_results.p\n",
    "        self.annotation_dict = raw_results.annotation_dict\n",
    "        self.global_clusters_sorted = raw_results.global_clusters_sorted\n",
    "        self.raw_results = raw_results.alignment_approach_results\n",
    "        \n",
    "        # 2D lists of length self.n corresponding to the proteins in self.p: [[{cluster_ids},count]]\n",
    "        self.true_positive, self.false_positive, self.false_negative = (\n",
    "            compare(self.p, self.annotation_dict, self.raw_results))\n",
    "        \n",
    "        self.global_percentile_actual = get_global_percentile_actual(self.p, self.true_positive, self.annotation_dict,\n",
    "                                                                     self.global_clusters_sorted)\n",
    "        self.global_percentile = get_global_percentile(self.p, self.true_positive, self.annotation_dict, \n",
    "                                                       self.global_clusters_sorted)\n",
    "        self.local_percentile = get_local_percentile(self.p, self.true_positive, self.annotation_dict, \n",
    "                                                     self.global_clusters_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f47b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms of true positive predictions of protein clusters in global cluster size distribution\n",
    "def get_global(results, r, a):\n",
    "    \n",
    "    if a == \"maj\": color = \"#ff5e57\"; edgecolor=\"#ff3f34\"\n",
    "    elif a == \"ff\": color = \"#0be881\"; edgecolor=\"#05c46b\"\n",
    "    elif a == \"sa\": color = \"#4bcffa\"; edgecolor=\"#0fbcf9\"\n",
    "    \n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append([])\n",
    "    for result in results:\n",
    "        for p in range(len(result.global_percentile)):\n",
    "            percentile[p].append(result.global_percentile[p])\n",
    "    for i in range(len(percentile)):\n",
    "        totalfori = 0\n",
    "        for j in range(len(percentile[i])):\n",
    "            totalfori += percentile[i][j]\n",
    "        totalfori//=len(percentile[i])\n",
    "        percentile[i] = totalfori\n",
    "    fr_this_time = []\n",
    "    for i in range(50):\n",
    "        fr_this_time.append(0)\n",
    "    for i in range(50):\n",
    "        totalfori = 0\n",
    "        for j in range(2):\n",
    "            totalfori+=percentile[2*i+j]\n",
    "        totalfori/=2\n",
    "        fr_this_time[i] = totalfori\n",
    "    left = []\n",
    "    for i in range(50):\n",
    "        left.append(i)\n",
    "    height = fr_this_time\n",
    "    tick_label = ['0','','','','','10','','','','','20','','','','','30','','','','', '40','','','','',\n",
    "                 '50','','','','','60','','','','','70','','','','','80','','','','', '90','','','','']\n",
    "    plt.bar(left, height, tick_label = tick_label, width = 1, color = color, edgecolor=edgecolor, alpha=0.8)\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel(\"Global Cluster Size Percentiles\")\n",
    "    plt.ylabel(\"% Correctly Predicted\")\n",
    "    plt.title(results[0].global_title)\n",
    "    bucket = \"global-2\"\n",
    "    if a == \"maj\":\n",
    "        plt.savefig(\"results/maj/{}-{}-{}.png\".format(bucket, str(r), a))\n",
    "    elif a == \"ff\":\n",
    "        plt.savefig(\"results/ff/{}-{}-{}.png\".format(bucket, str(r), a))\n",
    "    elif a == \"sa\":\n",
    "        plt.savefig(\"results/sa/{}-{}-{}.png\".format(bucket, str(r), a))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e8abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms of true positive predictions of protein clusters in local cluster size distribution\n",
    "def get_local(results, r, a):\n",
    "    if a == \"maj\": color = \"#ff5e57\"; edgecolor=\"#ff3f34\"\n",
    "    elif a == \"ff\": color = \"#0be881\"; edgecolor=\"#05c46b\"\n",
    "    elif a == \"sa\": color = \"#4bcffa\"; edgecolor=\"#0fbcf9\"\n",
    "        \n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append([])\n",
    "    for i in range(100):\n",
    "        for result in results:\n",
    "            percentile[i].append(result.local_percentile[i]*100)\n",
    "    for i in range(len(percentile)):\n",
    "        totalfori = 0\n",
    "        for j in range(len(percentile[i])):\n",
    "            totalfori += percentile[i][j]\n",
    "        totalfori//=len(percentile[i])\n",
    "        percentile[i] = totalfori\n",
    "    fr_this_time = []\n",
    "    for i in range(50):\n",
    "        fr_this_time.append(0)\n",
    "    for i in range(50):\n",
    "        totalfori = 0\n",
    "        for j in range(2):\n",
    "            totalfori+=percentile[2*i+j]\n",
    "        totalfori/=2\n",
    "        fr_this_time[i] = totalfori\n",
    "    left = []\n",
    "    for i in range(50):\n",
    "        left.append(i)\n",
    "    height = fr_this_time\n",
    "    tick_label = ['0','','','','','10','','','','','20','','','','','30','','','','', '40','','','','',\n",
    "                 '50','','','','','60','','','','','70','','','','','80','','','','', '90','','','','']\n",
    "    plt.bar(left, height, tick_label = tick_label, width = 1, color = color, edgecolor=edgecolor, alpha=0.8)\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel(\"Local Cluster Size Percentiles\")\n",
    "    plt.ylabel(\"% Correctly Predicted\")\n",
    "    plt.title(results[0].local_title)\n",
    "    bucket = \"local-2\"\n",
    "    if a == \"maj\":\n",
    "        plt.savefig(\"results/maj/{}-{}-{}.png\".format(bucket, str(r), a))\n",
    "    elif a == \"ff\":\n",
    "        plt.savefig(\"results/ff/{}-{}-{}.png\".format(bucket, str(r), a))\n",
    "    elif a == \"sa\":\n",
    "        plt.savefig(\"results/sa/{}-{}-{}.png\".format(bucket, str(r), a))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ed0bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results held here\n",
    "majority_list = {n: [] for n in range(1, 6)}\n",
    "flow_list = {n: [] for n in range(1, 6)}\n",
    "align_list = {n: [] for n in range(1, 6)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f036baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a trial for all methods at radius r\n",
    "def run_trial(r, n_iter=50):\n",
    "    for i in range(n_iter):\n",
    "        print(\"ITER {} / {}\".format(i+1, n_iter))\n",
    "\n",
    "        try:\n",
    "            results = RawResults(\"ecoli\", 5, r, do_alignment=True)\n",
    "\n",
    "            # perform majority neighbor\n",
    "            majority_results = MajorityApproachResults(results)\n",
    "            majority_list[r].append(majority_results)\n",
    "\n",
    "            # perform functional flow\n",
    "            flow_results = FunctionalFlowResults(results)\n",
    "            flow_list[r].append(flow_results)\n",
    "\n",
    "            # perform sequence alignment\n",
    "            align_results = AlignmentApproachResults(results)\n",
    "            align_list[r].append(align_results)\n",
    "        except:\n",
    "            # ran into an issue ... continue on next iteration\n",
    "            print(\"ERROR! CONTINUING FROM ITER {}...\".format(i+1))\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7901ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather global and local stats for all methods at radius r\n",
    "def get_radii_stats(r):\n",
    "    # radius r statistics\n",
    "    get_global(majority_list_radius_1, r=r, a=\"maj\")\n",
    "    get_global(flow_list_radius_1, r=r, a=\"ff\")\n",
    "    get_global(align_list_radius_1, r=r, a=\"sa\")\n",
    "\n",
    "    get_local(majority_list_radius_1, r=r, a=\"maj\")\n",
    "    get_local(flow_list_radius_1, r=r, a=\"ff\")\n",
    "    get_local(align_list_radius_1, r=r, a=\"sa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7546ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run trials for all tested radii\n",
    "run_trial(1)\n",
    "run_trial(2)\n",
    "run_trial(3)\n",
    "run_trial(4)\n",
    "run_trial(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f170d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather global and local statistics for all tested radii\n",
    "get_radii_stats(1)\n",
    "get_radii_stats(2)\n",
    "get_radii_stats(3)\n",
    "get_radii_stats(4)\n",
    "get_radii_stats(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b204acc9",
   "metadata": {},
   "source": [
    "### Testing Implementations\n",
    "The above code and classes run tests for each of the three methods implemented in the paper and radii 1 through 5. To run a test of the three methods, use the `run_trial(r)` method where `r` is the radius. To see the plots of global and local specificity after the trial is run, use the `get_radii_stats(r)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba5bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyResults():\n",
    "    def __init__(self, organism_name):\n",
    "        self.organism_name = organism_name\n",
    "        self.data_explorer = DataExplorer(organism_name)\n",
    "        \n",
    "    def jaccard(self, pred_labels, true_labels, weights=None):\n",
    "        # compute weighted/non-weighted jaccard distance between true and predicted labels\n",
    "        # smaller weights indicate higher importance\n",
    "\n",
    "        pred_labels = set(pred_labels)\n",
    "        true_labels = set(true_labels)\n",
    "\n",
    "        intersection = pred_labels.intersection(true_labels)\n",
    "        union = pred_labels.union(true_labels)\n",
    "\n",
    "        if weights:\n",
    "            intersection_size = sum([\n",
    "                (1 / weights[label]) for label in intersection\n",
    "            ])\n",
    "\n",
    "            union_size = sum([\n",
    "                (1 / weights[label]) for label in union\n",
    "            ])\n",
    "        else:\n",
    "            intersection_size = len(intersection)\n",
    "            union_size = len(union)\n",
    "\n",
    "        return intersection_size / union_size\n",
    "\n",
    "    def precision(self, pred_labels, true_labels, weights=None):\n",
    "        # compute weighted/non-weighted precision between true and predicted labels\n",
    "        # smaller weights indicate higher importance\n",
    "\n",
    "        pred_labels = set(pred_labels)\n",
    "        true_labels = set(true_labels)\n",
    "\n",
    "        intersection = pred_labels.intersection(true_labels)\n",
    "\n",
    "        if weights:\n",
    "            intersection_size = sum([\n",
    "                (1 / weights[label]) for label in intersection\n",
    "            ])\n",
    "\n",
    "            pred_size = sum([\n",
    "                (1 / weights[label]) for label in pred_labels\n",
    "            ])\n",
    "        else:\n",
    "            intersection_size = len(intersection)\n",
    "            pred_size = len(pred_labels)\n",
    "\n",
    "        return intersection_size / pred_size\n",
    "\n",
    "    def recall(self, pred_labels, true_labels, weights=None):\n",
    "        # compute weighted/non-weighted recall between true and predicted labels\n",
    "        # smaller weights indicate higher importance\n",
    "\n",
    "        pred_labels = set(pred_labels)\n",
    "        true_labels = set(true_labels)\n",
    "\n",
    "        intersection = pred_labels.intersection(true_labels)\n",
    "        false_negatives = true_labels.difference(pred_labels)\n",
    "\n",
    "        if weights:\n",
    "            intersection_size = sum([\n",
    "                (1 / weights[label]) for label in intersection\n",
    "            ])\n",
    "\n",
    "            false_negative_size = sum([\n",
    "                (1 / weights[label]) for label in false_negatives\n",
    "            ])\n",
    "        else:\n",
    "            intersection_size = len(intersection)\n",
    "            false_negative_size = len(false_negatives)\n",
    "\n",
    "        return intersection_size / (intersection_size + false_negative_size)\n",
    "\n",
    "    def f1_score(self, pred_labels, true_labels, weights=None):\n",
    "        precision_score = precision(pred_labels, true_labels, weights)\n",
    "        recall_score = recall(pred_labels, true_labels, weights)\n",
    "\n",
    "        return (2 * precision_score * recall_score) / (precision_score + recall_score)\n",
    "    \n",
    "    def compute_scores(self, method):\n",
    "        if method == \"maj\":\n",
    "            res = [majority_list[i] for i in majority_list]\n",
    "        elif method == \"ff\":\n",
    "            res = [flow_list[i] for i in flow_list]\n",
    "        elif method == \"sa\":\n",
    "            res = [align_list[i] for i in align_list]\n",
    "        \n",
    "        scores = scores = {n : {\n",
    "                \"jaccard\": {\"weighted\": 0, \"nonweighted\": 0},\n",
    "                \"precision\": {\"weighted\": 0, \"nonweighted\": 0},\n",
    "                \"recall\": {\"weighted\": 0, \"nonweighted\": 0},\n",
    "                \"f1\": {\"weighted\": 0, \"nonweighted\": 0}} for n in range(1, 6)\n",
    "        }\n",
    "        \n",
    "        for n in range(len(res)):\n",
    "            cnt = 0\n",
    "            for trial in res[n]:\n",
    "                for i in range(len(trial.p)):\n",
    "                    cnt += 1\n",
    "\n",
    "                    tp, _ = trial.true_positive[i]\n",
    "                    fp, _ = trial.false_positive[i]\n",
    "\n",
    "                    pred_labels = list(tp) + list(fp)\n",
    "                    true_labels = data_explorer.annotation_list[trial.p[i]]\n",
    "                    try:\n",
    "                        majority_scores[n+1][\"jaccard\"][\"weighted\"] += self.jaccard(pred_labels,true_labels,weights)\n",
    "                        majority_scores[n+1][\"jaccard\"][\"nonweighted\"] += self.jaccard(pred_labels,true_labels)\n",
    "                    except: cnt -= 1\n",
    "\n",
    "                    try:\n",
    "                        majority_scores[n+1][\"precision\"][\"weighted\"] += self.precision(pred_labels,true_labels,weights)\n",
    "                        majority_scores[n+1][\"precision\"][\"nonweighted\"] += self.precision(pred_labels,true_labels)\n",
    "                    except: cnt -= 1\n",
    "\n",
    "                    try:\n",
    "                        majority_scores[n+1][\"recall\"][\"weighted\"] += self.recall(pred_labels,true_labels,weights)\n",
    "                        majority_scores[n+1][\"recall\"][\"nonweighted\"] += self.recall(pred_labels,true_labels)\n",
    "                    except: cnt -= 1\n",
    "\n",
    "                    try:\n",
    "                        majority_scores[n+1][\"f1\"][\"weighted\"] += self.f1_score(pred_labels,true_labels,weights)\n",
    "                        majority_scores[n+1][\"f1\"][\"nonweighted\"] += self.f1_score(pred_labels,true_labels)\n",
    "                    except: cnt -= 1\n",
    "                        \n",
    "            for method in majority_scores[n+1]:\n",
    "                for w in majority_scores[n+1][method]:\n",
    "                    majority_scores[n+1][method][w] /= cnt\n",
    "\n",
    "        print(\"--- {} SCORES (ACCURACY) ---\".format(method))\n",
    "        pprint.pprint(majority_scores)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def visualize_accuracies(self, w, method):\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        width=0.3\n",
    "        x = np.arange(len([1, 2, 3, 4, 5]))\n",
    "        \n",
    "        y1 = [round(majority_scores[1][method][w], 3),\n",
    "              round(majority_scores[2][method][w], 3),\n",
    "              round(majority_scores[3][method][w], 3),\n",
    "              round(majority_scores[4][method][w], 3)]\n",
    "\n",
    "        y2 = [round(ff_scores[1][method][w], 3),\n",
    "              round(ff_scores[2][method][w], 3),\n",
    "              round(ff_scores[3][method][w], 3),\n",
    "              round(ff_scores[4][method][w], 3)]\n",
    "\n",
    "        y3 = [round(sa_scores[1][method][w], 3),\n",
    "              round(sa_scores[2][method][w], 3), 0, 0]\n",
    "\n",
    "        b1 = ax.bar(x - width, y1, width, label=\"Majority\", color=\"#ff5e57\",edgecolor=\"#ff3f34\")\n",
    "        b2 = ax.bar(x, y3, width, label=\"Alignment\", color=\"#4bcffa\",edgecolor=\"#0fbcf9\")\n",
    "        b3 = ax.bar(x + width, y2, width, label=\"Flow\", color=\"#0be881\",edgecolor=\"#05c46b\")\n",
    "\n",
    "        ax.bar_label(b1, padding=3)\n",
    "        ax.bar_label(b2, padding=3)\n",
    "        ax.bar_label(b3, padding=3)\n",
    "        ax.set_xticks(x, [\"r=1\", \"r=2\", \"r=3\", \"r=4\", \"r=5\"])\n",
    "        ax.set_ylim([0, 1.1])\n",
    "\n",
    "        ax.set_title(\"Average Weighted F1 Scores ({})\".format(self.organism_name))\n",
    "        ax.set_ylabel(\"{} Score ({})\".format(method, w))\n",
    "        ax.set_xlabel(\"Tested Radii\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.legend(loc='upper right')\n",
    "\n",
    "        plt.savefig(\"results/{}-scores-{}.png\".format(method, w))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d8d939",
   "metadata": {},
   "source": [
    "### Testing Implementations (pt. 2)\n",
    "Once you have gathered data about each implementation for a number of radii, you may visualize and analyze the accuracy of each model through the Jaccard index, precision score, recall score, and F1 score. To view accuracy information, use the `compute_scores(m)` function where `m` is one of `{\"maj\", \"ff\", \"sa}`, corresponding to each method. You may also view a plot of the accuracy with the `visualize_accuracies(w, m)` function where `w` is one of `{\"weighted\", \"nonweighted\"}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f23370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_plot():\n",
    "    clusters = data_explorer.cluster_sizes\n",
    "    sizes = sorted(list(clusters.values()))[::-1]\n",
    "    \n",
    "    print(statistics.median(sizes))\n",
    "    \n",
    "    plt.plot(sizes, color = \"#0984e3\")\n",
    "    plt.fill_between(range(len(sizes)), 0, sizes, color=\"#74b9ff\", alpha=0.2)\n",
    "    \n",
    "    plt.title(\"Cluster Size Distribution (E. coli)\")\n",
    "    plt.xlabel(\"Cluster ID\")\n",
    "    plt.ylabel(\"Cluster size\")\n",
    "    plt.savefig(\"cluster-dist.png\")\n",
    "\n",
    "    cluster_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c0bcb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cluster_protein():\n",
    "    kz = data_explorer.adj_list.keys()\n",
    "    random_proteins = kz\n",
    "    \n",
    "    sizes = []\n",
    "    for protein in random_proteins:\n",
    "        for c in data_explorer.annotation_list[protein]:\n",
    "            sizes.append(data_explorer.cluster_sizes[c])\n",
    "    \n",
    "    plt.title(\"Protein Cluster Distribution (E. coli)\")\n",
    "    plt.xlabel(\"Cluster size\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.hist(sizes, bins=30, color=\"#74b9ff\", edgecolor='#0984e3', alpha=0.8)\n",
    "    plt.savefig(\"protein-dist.png\")\n",
    "\n",
    "cluster_protein()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aebbeb",
   "metadata": {},
   "source": [
    "### Network Statistics (p. 2)\n",
    "The above code is there to visualize information about cluster sizes and display the cluster size heirarchy and class imbalance present within many STRING organisms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
