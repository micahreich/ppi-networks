{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d106b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import statistics\n",
    "import os\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86616f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExplorer():\n",
    "    def __init__(self, organism_name, t=0.3):\n",
    "        self.organism_name = organism_name\n",
    "        \n",
    "        # find relevant files for clusters, protein links, protein info, and protein sequences\n",
    "        self.data_dir = \"data\"\n",
    "        self.data_files = os.listdir(self.data_dir + \"/{}/\".format(organism_name))\n",
    "        \n",
    "        for file in self.data_files:\n",
    "            if \"protein\" in file and \"links\" in file:\n",
    "                self.links_file = self.data_dir + \"/{}/\".format(organism_name) + file\n",
    "                \n",
    "        for file in self.data_files:\n",
    "            if \"protein\" in file and \"info\" in file:\n",
    "                self.info_file = self.data_dir + \"/{}/\".format(organism_name) + file\n",
    "        \n",
    "        for file in self.data_files:\n",
    "            if \"cluster\" in file and \"protein\" in file:\n",
    "                self.cluster_links_file = self.data_dir + \"/{}/\".format(organism_name) + file\n",
    "        \n",
    "        for file in self.data_files:\n",
    "            if \"cluster\" in file and \"info\" in file:\n",
    "                self.cluster_desc_file = self.data_dir + \"/{}/\".format(organism_name) + file\n",
    "        \n",
    "        for file in self.data_files:\n",
    "            if \"protein\" in file and \"sequences\" in file:\n",
    "                self.seq_file = self.data_dir + \"/{}/\".format(organism_name) + file\n",
    "        \n",
    "        self.adj_list = self.make_adj_list(self.make_protein_links(), t)\n",
    "        self.filtered_names_set, self.filtered_names_list = (\n",
    "            self.filter_protein_names(self.adj_list))\n",
    "        \n",
    "        self.cluster_sizes = self.make_cluster_sizes()\n",
    "        self.clusters_sorted = self.sort_clusters()\n",
    "        self.annotation_list = self.make_annotation_list()\n",
    "        self.cluster_size_mean = self.get_mean()\n",
    "        self.cluster_size_std_dev = self.get_std_dev()\n",
    "        self.sequences = self.make_sequence_list()\n",
    "    \n",
    "    # clean up the STRING links file\n",
    "    def make_protein_links(self):\n",
    "        with open(self.links_file) as file:\n",
    "            lines = []\n",
    "            for line in file:\n",
    "                lines.append(line.split())\n",
    "            protein_links = lines\n",
    "        file.close()\n",
    "        \n",
    "        return protein_links[1:]\n",
    "    \n",
    "    # compile a list of all protein names in the PPIN\n",
    "    def make_protein_names(self):\n",
    "        with open(self.info_file) as file:\n",
    "            lines = []\n",
    "            for line in file:\n",
    "                lines.append(line.split()[0:2])\n",
    "            protein_names = lines\n",
    "        file.close()\n",
    "        \n",
    "        return protein_names[1:]\n",
    "    \n",
    "    # filter the names (unused) to get searchable tokens\n",
    "    def filter_protein_names(self, protein_names):\n",
    "        protein_names_filtered_set = set()\n",
    "        protein_names_filtered_list = []\n",
    "        protein_names_unfiltered = {}\n",
    "\n",
    "        for name in protein_names:\n",
    "            protein_names_filtered_set.add(name)\n",
    "            protein_names_filtered_list.append(name)\n",
    "        \n",
    "        return protein_names_filtered_set, protein_names_filtered_list\n",
    "    \n",
    "    # create adjacency list (dict) based on protein links from STRING\n",
    "    def make_adj_list(self, protein_links, t):\n",
    "        protein_links_dict = {}\n",
    "\n",
    "        for link in protein_links:\n",
    "            protein_1, protein_2, score = link\n",
    "            \n",
    "            # only add edges whose weight exceeds the parameter threshold t\n",
    "            if (int(score) / 1000) < t:\n",
    "                if protein_1 not in protein_links_dict: \n",
    "                    protein_links_dict[protein_1] = []\n",
    "            else:\n",
    "                if protein_1 not in protein_links_dict: \n",
    "                    protein_links_dict[protein_1] = [(protein_2, round(int(score) / 1000, 7))]\n",
    "                else:\n",
    "                    protein_links_dict[protein_1].append((protein_2, round(int(score) / 1000, 7)))\n",
    "        \n",
    "        cpy = copy.deepcopy(protein_links_dict)\n",
    "        for protein in cpy:\n",
    "            if len(protein_links_dict[protein]) == 0:\n",
    "                del protein_links_dict[protein]\n",
    "        \n",
    "        return protein_links_dict\n",
    "    \n",
    "    # gather protein function annotations for proteins in the PPIN\n",
    "    def make_annotation_list(self):\n",
    "        with open(self.cluster_links_file) as file:\n",
    "            lines = []\n",
    "            for line in file:\n",
    "                lines.append(line.split()[1:3])\n",
    "            protein_clusters = lines\n",
    "        file.close()\n",
    "        \n",
    "        protein_clusters_dict = {}\n",
    "        \n",
    "        for (cluster_id, protein_id) in protein_clusters[1:]:\n",
    "            cluster_id_clean = cluster_id[cluster_id.index(\":\") + 1:]\n",
    "            \n",
    "            if protein_id not in protein_clusters_dict:\n",
    "                protein_clusters_dict[protein_id] = [cluster_id_clean]\n",
    "            else:\n",
    "                protein_clusters_dict[protein_id].append(cluster_id_clean)\n",
    "        \n",
    "        for protein_id in protein_clusters_dict:\n",
    "            clusters_w_sizes = zip(protein_clusters_dict[protein_id], \n",
    "                                   [self.cluster_sizes[cluster] for cluster in protein_clusters_dict[protein_id]]\n",
    "                                  )\n",
    "            sorted_clusters = sorted(clusters_w_sizes, key=lambda tup: tup[1])\n",
    "            protein_clusters_dict[protein_id] = [p for (p, _) in sorted_clusters]\n",
    "            \n",
    "        return protein_clusters_dict\n",
    "    \n",
    "    # compile information about cluster sizes for each cluster in the PPIN\n",
    "    def make_cluster_sizes(self):\n",
    "        with open(self.cluster_desc_file) as file:\n",
    "            lines = []\n",
    "            for line in file:\n",
    "                lines.append(line.split()[1:3])\n",
    "            cluster_sizes = lines\n",
    "        file.close()\n",
    "        \n",
    "        cluster_sizes_dict = {}\n",
    "        \n",
    "        for (cluster_id, size) in cluster_sizes[1:]:\n",
    "            cluster_id_clean = cluster_id[cluster_id.index(\":\") + 1:]\n",
    "            \n",
    "            cluster_sizes_dict[cluster_id_clean] = int(size)\n",
    "        \n",
    "        return cluster_sizes_dict\n",
    "    \n",
    "    # compile amino acid sequence data for each protein in the PPIN\n",
    "    def make_sequence_list(self):\n",
    "        with open(self.seq_file) as file:\n",
    "            lines = {}\n",
    "            protein_id = \"\"\n",
    "            \n",
    "            for line in file:\n",
    "                if line.startswith(\">\"):\n",
    "                    protein_id = line[line.index(\">\") + 1:].strip()\n",
    "                    lines[protein_id] = \"\"\n",
    "                else:\n",
    "                    lines[protein_id] += line.strip()\n",
    "        return lines\n",
    "            \n",
    "    # statistical helper functions for working with cluster size percentiles\n",
    "    def get_mean(self):\n",
    "        size_sum = 0\n",
    "        for size in self.cluster_sizes:\n",
    "            size_sum += self.cluster_sizes[size]\n",
    "        number_of_sizes = len(self.cluster_sizes)\n",
    "        return size_sum/number_of_sizes\n",
    "        \n",
    "    def get_std_dev(self):\n",
    "        size_sum = 0 \n",
    "        for size in self.cluster_sizes:\n",
    "            size_sum += (abs((self.cluster_sizes[size]-self.cluster_size_mean))**2)\n",
    "        number_of_sizes = len(self.cluster_sizes)\n",
    "        std_dev = math.sqrt(size_sum/number_of_sizes)\n",
    "        return std_dev\n",
    "    \n",
    "    def sort_clusters(self):\n",
    "        size_list = []\n",
    "        cluster_sizes = copy.copy(self.cluster_sizes)\n",
    "        for size in cluster_sizes:\n",
    "            size_list.append(cluster_sizes[size])\n",
    "        size_list.sort()\n",
    "        size_list.reverse()\n",
    "        clusters_sorted = []\n",
    "        for i in range(len(size_list)):\n",
    "            for j in cluster_sizes:\n",
    "                if cluster_sizes[j] == size_list[i]:\n",
    "                    clusters_sorted.append(j)\n",
    "                    del cluster_sizes[j]\n",
    "                    break\n",
    "        return clusters_sorted "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243659b",
   "metadata": {},
   "source": [
    "### Usage of ``DataExplorer`` class\n",
    "To create a new instance of the class, create a new variable with the organism name (whose data content is stored in the `data/` subdirectory:\n",
    "```\n",
    "ecoli_explorer = DataExplorer(\"ecoli\")\n",
    "```\n",
    "Creating a new instance of the `DataExplorer` class for an organism computes all the relevant instance variables like the PPIN adjacency list, the cluster sizes for the organism, and the protein sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6fc114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(obj):\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # calculate average degree\n",
    "    node_degrees = [len(obj.adj_list[i]) for i in obj.adj_list]\n",
    "    degree_mean = sum(node_degrees) / len(node_degrees)\n",
    "    \n",
    "    # calculate graph density\n",
    "    max_edges = int(len(obj.adj_list) * (len(obj.adj_list) - 1) / 2)\n",
    "    number_edges = int(sum(node_degrees) / 2) # woah handshake lemma\n",
    "    \n",
    "    # calculate number of proteins\n",
    "    n_proteins = len(obj.adj_list)\n",
    "    \n",
    "    # calculate avg degree / number proteins\n",
    "    degree_ratio = degree_mean / n_proteins\n",
    "    \n",
    "    # calculate average score\n",
    "    scores = []\n",
    "    \n",
    "    for prot in obj.adj_list:\n",
    "        for interaction in obj.adj_list[prot]:\n",
    "            scores.append(interaction[1])\n",
    "    \n",
    "    score_mean = sum(scores) / (2 * number_edges)\n",
    "    \n",
    "    n_bins = int(1 + 3.22 * math.log(len(node_degrees)))\n",
    "    \n",
    "    p = plt.hist(node_degrees, bins = n_bins, color=\"#575fcf\", edgecolor=\"#3c40c6\", alpha=0.8)\n",
    "    # p.set_transform(ax.transAxes)\n",
    "    # p.set_clip_on(False)\n",
    "\n",
    "    plt.title(\"PPI Network Degree Histogram ({})\".format(obj.organism_name))\n",
    "    plt.xlabel(\"Node degrees\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    font = {\n",
    "        'size': 14,\n",
    "    }\n",
    "    \n",
    "    ax.text(0.4,0.65, \"# Nodes: {}\\nAverage degree: {}\\nDensity ([0,1]): {}\"\n",
    "             .format(str(n_proteins), str(round(degree_mean, 3)), str(round(number_edges / max_edges, 3))),\n",
    "             bbox=dict(facecolor='#d2dae2', alpha=0.2), fontdict=font, transform=ax.transAxes)\n",
    "    \n",
    "    plt.savefig(\"{}-ppi-histogram.jpg\".format(obj.organism_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd75e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_datasets():\n",
    "    subfolders = [f for f in os.scandir(\"data\") if f.is_dir()]\n",
    "    \n",
    "    for orgsm in subfolders:\n",
    "        orgsm_name = orgsm.name\n",
    "        orgsm_explorer = DataExplorer(orgsm_name)\n",
    "        \n",
    "        make_plot(orgsm_explorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2eaded",
   "metadata": {},
   "source": [
    "### Visualizing PPINs\n",
    "To visualize network statistics about an organisms PPIN, use the `plot_datasets()` function to generate histograms of node degrees, including information about the number of proteins, average node degree, and network density of an organism's PPIN. \"Density\" refers to the ratio of actual number of edges to total possible number of edges in a complete graph of n nodes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
