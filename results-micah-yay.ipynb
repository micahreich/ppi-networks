{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3eaa999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/testenv/lib/python3.8/site-packages/Bio/SubsMat/__init__.py:126: BiopythonDeprecationWarning: Bio.SubsMat has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.substitution_matrices as a replacement, and contact the Biopython developers if you still need the Bio.SubsMat module.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1117\n"
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "import json\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import statistics\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "from ipynb.fs.full.data_explore import DataExplorer\n",
    "from ipynb.fs.full.function_prediction import FunctionPrediction\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ba2df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RawResults class holds all info \n",
    "class RawResults():\n",
    "    def __init__(self, organism_name, n, r):\n",
    "        \n",
    "        # folder name\n",
    "        self.organism_name = organism_name\n",
    "        # length of list of proteins\n",
    "        self.n = n\n",
    "        # radius or timestep\n",
    "        self.r = r\n",
    "        \n",
    "        # adjustable variables for raw scoring that we currently do not use\n",
    "        self.true_positive_reward = 1\n",
    "        self.false_positive_penalty = -0.25\n",
    "        self.false_negative_penalty = -0.25\n",
    "        \n",
    "        # DataExplorer\n",
    "        self.data_explorer = DataExplorer(self.organism_name)\n",
    "        # used to get the actual list of annotations for a protein: self.annotation_dict[self.p[p]]\n",
    "        self.annotation_dict = self.data_explorer.annotation_list\n",
    "        # used in get_test_proteins() to gather self.p\n",
    "        self.names_set = self.data_explorer.filtered_names_set\n",
    "        self.names_list = self.data_explorer.filtered_names_list\n",
    "        # used in get_global/local_percentile_ to get list of glosters sorted by size\n",
    "        self.global_clusters_sorted = self.data_explorer.clusters_sorted\n",
    "        \n",
    "        # gathering list of test proteins\n",
    "        self.p = self.get_test_proteins(n)\n",
    "        print(self.p)\n",
    "        # FunctionPrediction\n",
    "        function_predictor = FunctionPrediction(self.organism_name)\n",
    "        # raw results \n",
    "#         print(\"starting majority\")\n",
    "        self.majority_approach_results = function_predictor.majority_rule(self.p, r=self.r)\n",
    "#         print(\"did majority\")\n",
    "#         print(\"starting ff\")\n",
    "        self.functional_flow_results = function_predictor.functional_flow(self.p, t=self.r)\n",
    "#         print(\"did majority\")\n",
    "        self.alignment_approach_results = function_predictor.alignment_approach(self.p, r=self.r)\n",
    "\n",
    "    # returns a random size n list of proteins to test\n",
    "    def get_test_proteins(self, n):\n",
    "#         p = []\n",
    "#         for x in range(n):\n",
    "#             i = random.randint(0, len(self.names_set))\n",
    "#             while self.names_list[i] in p:\n",
    "#                 i = random.randint(0, len(self.names_set))\n",
    "#                 while len(self.annotation_dict[self.names_list[i]]) == 0:\n",
    "#                     i = random.randint(0, len(self.names_set))\n",
    "#             p.append(self.names_list[i])\n",
    "        kz = self.data_explorer.adj_list.keys()\n",
    "        return random.sample(kz, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8322dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compares results from FunctionPrediction to actual\n",
    "def compare(p, annotation, results):\n",
    "    true_positive = []\n",
    "    false_positive = []\n",
    "    false_negative = []\n",
    "    for i in range(len(p)):\n",
    "        protein = p[i]\n",
    "        true_positive.append([set(), 0])\n",
    "        false_positive.append([set(), 0])\n",
    "        false_negative.append([set(), 0])\n",
    "        actual_clusters = copy.deepcopy(annotation[protein])\n",
    "        result_clusters = results[protein]\n",
    "        if len(result_clusters) >= len(actual_clusters):\n",
    "            for j in range(len(actual_clusters)):\n",
    "                cluster = result_clusters[j]\n",
    "                if cluster in actual_clusters:\n",
    "                    true_positive[i][0].add(cluster)\n",
    "                    true_positive[i][1] += 1\n",
    "                    actual_clusters.remove(cluster)\n",
    "                elif cluster not in actual_clusters:\n",
    "                    false_positive[i][0].add(cluster)\n",
    "                    false_positive[i][1] += 1\n",
    "            for cluster in actual_clusters:\n",
    "                false_negative[i][0].add(cluster)\n",
    "                false_negative[i][1] += 1\n",
    "        elif len(result_clusters) < len(actual_clusters):\n",
    "            for j in range(len(result_clusters)):\n",
    "                cluster = actual_clusters[j]\n",
    "                if cluster in result_clusters:\n",
    "                    true_positive[i][0].add(cluster)\n",
    "                    true_positive[i][1] += 1\n",
    "                    result_clusters.remove(cluster)\n",
    "                elif cluster not in result_clusters:\n",
    "                    false_negative[i][0].add(cluster)\n",
    "                    false_negative[i][1] += 1\n",
    "            for cluster in result_clusters:\n",
    "                false_positive[i][0].add(cluster)\n",
    "                false_positive[i][1] += 1\n",
    "    return true_positive, false_positive, false_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00e6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds where actual protein clusters fall in the global cluster size distribution\n",
    "def get_global_percentile_actual(p, true_positive, annotation_dict, global_clusters_sorted):\n",
    "    percentile = []\n",
    "    for protein in range(len(p)):\n",
    "        for c in annotation_dict[p[protein]]:\n",
    "            i = global_clusters_sorted.index(c)\n",
    "            percentile.append((i/len(global_clusters_sorted)*100)//1)\n",
    "    listof100actual = []\n",
    "    totallen = 0\n",
    "    for protein in range(len(p)):\n",
    "        totallen = len(annotation_dict[p[protein]])\n",
    "    for i in range(100):\n",
    "        listof100actual.append((percentile.count(i)/totallen*100)//(len(p)))\n",
    "    return listof100actual\n",
    "\n",
    "# finds where true positive predictions of protein clusters fall in the global cluster size distribution\n",
    "def get_global_percentile(p, true_positive, annotation_dict, global_clusters_sorted):\n",
    "    percentile = []\n",
    "    for protein in range(len(p)):\n",
    "        for c in annotation_dict[p[protein]]:\n",
    "            i = global_clusters_sorted.index(c)\n",
    "            percentile.append((i/len(global_clusters_sorted)*100)//1)\n",
    "    listof100actual = []\n",
    "    totallen = 0\n",
    "    for protein in range(len(p)):\n",
    "        totallen = len(annotation_dict[p[protein]])\n",
    "    for i in range(100):\n",
    "        listof100actual.append((percentile.count(i)))\n",
    "    listof100avg = []\n",
    "    for i in range(100):\n",
    "        listof100avg.append([])\n",
    "    percentile = []\n",
    "    for protein in range(len(p)):\n",
    "        for tp in true_positive[protein][0]:\n",
    "            i = global_clusters_sorted.index(tp)\n",
    "            percentile.append((i/len(global_clusters_sorted)*100)//1)\n",
    "        listof100result = []\n",
    "        for i in range(100):\n",
    "            listof100result.append(percentile.count(i))\n",
    "        for i in range(100):\n",
    "            listof100avg[i].append(listof100result[i])\n",
    "    for i in range(100):\n",
    "        totalfori = 0\n",
    "        for j in range(len(listof100avg[i])):\n",
    "            totalfori += listof100avg[i][j]\n",
    "        totalfori/=len(listof100avg[i])\n",
    "        listof100avg[i] = totalfori\n",
    "    listof100 = []\n",
    "    for i in range(100):\n",
    "        if listof100actual[i] == 0:\n",
    "            listof100.append(0)\n",
    "        else:\n",
    "            listof100.append(((listof100avg[i]/listof100actual[i])*100)//1)\n",
    "    return listof100\n",
    "        \n",
    "# finds where actual protein clusters fall in the local cluster size distribution\n",
    "def get_local_percentile(p, true_positive, annotation_dict, global_clusters_sorted):\n",
    "    clusters = []\n",
    "    cluster_len_total = 0\n",
    "    for protein in range(len(p)):\n",
    "        cluster_unsorted = annotation_dict[p[protein]]\n",
    "        cluster_sorted = []\n",
    "        for c in global_clusters_sorted:\n",
    "            if c in cluster_unsorted:\n",
    "                cluster_sorted.append(c)\n",
    "        clusters.append(cluster_sorted)\n",
    "        cluster_len_total += len(cluster_sorted)\n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append(0)\n",
    "    for i in range(len(p)):\n",
    "        tpi = true_positive[i]\n",
    "        ci = clusters[i]\n",
    "        for tp in tpi[0]:\n",
    "            percentile[int((ci.index(tp)/len(ci)*100)//1)]+=1\n",
    "    for i in range(100):\n",
    "        if percentile[i] != 0:\n",
    "            percentile[i] == (percentile[i]/(cluster_len_total/100)*100*100)\n",
    "    return percentile        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e2dd27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorityApproachResults():\n",
    "    def __init__(self, raw_results):\n",
    "        self.global_title = 'Global Specificity with Majority Approach'\n",
    "        self.global_color = 'red'\n",
    "        self.local_title = 'Local Specificity with Majority Approach'\n",
    "        self.local_color = 'orange'\n",
    "        \n",
    "        # info gathered from raw_results\n",
    "        self.p = raw_results.p\n",
    "        self.annotation_dict = raw_results.annotation_dict\n",
    "        self.global_clusters_sorted = raw_results.global_clusters_sorted\n",
    "        self.raw_results = raw_results.majority_approach_results\n",
    "        #self.tp_reward = raw_results.true_positive_reward\n",
    "        #self.fp_penalty = raw_results.false_positive_penalty\n",
    "        #self.fn_penalty = raw_results.false_negative_penalty\n",
    "        \n",
    "        # 2D lists of length self.n corresponding to the proteins in self.p: [[{cluster_ids},count]]\n",
    "        self.true_positive, self.false_positive, self.false_negative = (\n",
    "            compare(self.p, self.annotation_dict, self.raw_results))\n",
    "        \n",
    "        # not currently used\n",
    "        #self.scores = score(self.p, self.true_positive, self.false_positive, self.false_negative, \n",
    "                            #self.tp_reward, self.fp_penalty, self.fn_penalty, self.annotation_dict)\n",
    "        \n",
    "        self.global_percentile_actual = get_global_percentile_actual(self.p, self.true_positive, self.annotation_dict,\n",
    "                                                                     self.global_clusters_sorted)\n",
    "        self.global_percentile = get_global_percentile(self.p, self.true_positive, self.annotation_dict, \n",
    "                                                       self.global_clusters_sorted)\n",
    "        self.local_percentile = get_local_percentile(self.p, self.true_positive, self.annotation_dict, \n",
    "                                                     self.global_clusters_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21610f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionalFlowResults():\n",
    "    def __init__(self, raw_results):\n",
    "        self.global_title = 'Global Specificity with Functional Flow'\n",
    "        self.global_color = 'gold'\n",
    "        self.local_title = 'Local Specificity with Functional Flow'\n",
    "        self.local_color = 'green'\n",
    "        \n",
    "        # info gathered from raw_results\n",
    "        self.p = raw_results.p\n",
    "        self.annotation_dict = raw_results.annotation_dict\n",
    "        self.global_clusters_sorted = raw_results.global_clusters_sorted\n",
    "        self.raw_results = raw_results.functional_flow_results\n",
    "        #self.tp_reward = raw_results.true_positive_reward\n",
    "        #self.fp_penalty = raw_results.false_positive_penalty\n",
    "        #self.fn_penalty = raw_results.false_negative_penalty\n",
    "        \n",
    "        # 2D lists of length self.n corresponding to the proteins in self.p: [[{cluster_ids},count]]\n",
    "        self.true_positive, self.false_positive, self.false_negative = (\n",
    "            compare(self.p, self.annotation_dict, self.raw_results))\n",
    "        \n",
    "        # not currently used\n",
    "        #self.scores = score(self.p, self.true_positive, self.false_positive, self.false_negative, \n",
    "                            #self.tp_reward, self.fp_penalty, self.fn_penalty, self.annotation_dict)\n",
    "        \n",
    "        self.global_percentile_actual = get_global_percentile_actual(self.p, self.true_positive, self.annotation_dict,\n",
    "                                                                     self.global_clusters_sorted)\n",
    "        self.global_percentile = get_global_percentile(self.p, self.true_positive, self.annotation_dict, \n",
    "                                                       self.global_clusters_sorted)\n",
    "        self.local_percentile = get_local_percentile(self.p, self.true_positive, self.annotation_dict, \n",
    "                                                     self.global_clusters_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "707e56e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignmentApproachResults():\n",
    "    def __init__(self, raw_results):\n",
    "        self.global_title = 'Global Specificity with Alignment Approach'\n",
    "        self.global_color = 'blue'\n",
    "        self.local_title = 'Local Specificity with Alignment Approach'\n",
    "        self.local_color = 'purple'\n",
    "        \n",
    "        # info gathered from raw_results\n",
    "        self.p = raw_results.p\n",
    "        self.annotation_dict = raw_results.annotation_dict\n",
    "        self.global_clusters_sorted = raw_results.global_clusters_sorted\n",
    "        self.raw_results = raw_results.alignment_approach_results\n",
    "        #self.tp_reward = raw_results.true_positive_reward\n",
    "        #self.fp_penalty = raw_results.false_positive_penalty\n",
    "        #self.fn_penalty = raw_results.false_negative_penalty\n",
    "        \n",
    "        # 2D lists of length self.n corresponding to the proteins in self.p: [[{cluster_ids},count]]\n",
    "        self.true_positive, self.false_positive, self.false_negative = (\n",
    "            compare(self.p, self.annotation_dict, self.raw_results))\n",
    "        \n",
    "        # not currently used\n",
    "        #self.scores = score(self.p, self.true_positive, self.false_positive, self.false_negative, \n",
    "                            #self.tp_reward, self.fp_penalty, self.fn_penalty, self.annotation_dict)\n",
    "        \n",
    "        self.global_percentile_actual = get_global_percentile_actual(self.p, self.true_positive, self.annotation_dict,\n",
    "                                                                     self.global_clusters_sorted)\n",
    "        self.global_percentile = get_global_percentile(self.p, self.true_positive, self.annotation_dict, \n",
    "                                                       self.global_clusters_sorted)\n",
    "        self.local_percentile = get_local_percentile(self.p, self.true_positive, self.annotation_dict, \n",
    "                                                     self.global_clusters_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3604cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms of actual protein clusters in the global cluster size distribution\n",
    "def get_global_actual_bucket_1(results):\n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append([])\n",
    "    for result in results:\n",
    "        for p in range(len(result.global_percentile_actual)):\n",
    "            percentile[p].append(result.global_percentile_actual[p])\n",
    "    for i in range(len(percentile)):\n",
    "        totalfori = 0\n",
    "        for j in range(len(percentile[i])):\n",
    "            totalfori += percentile[i][j]\n",
    "        totalfori//= len(percentile[i])\n",
    "        percentile[i] = totalfori\n",
    "    left = []\n",
    "    for i in range(100):\n",
    "        left.append(i)\n",
    "    height = percentile\n",
    "    plt.bar(left, height, width = 1, color ='black')\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel(\"Global Cluster Size Percentiles\")\n",
    "    plt.ylabel(\"Percent of Protein Clusters in Percentile\")\n",
    "    plt.title(\"Global Cluster Size Distribution\")\n",
    "    plt.show()\n",
    "    \n",
    "def get_global_actual_bucket_2(results):\n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append([])\n",
    "    for result in results:\n",
    "        for p in range(len(result.global_percentile_actual)):\n",
    "            percentile[p].append(result.global_percentile_actual[p])\n",
    "    for i in range(len(percentile)):\n",
    "        totalfori = 0\n",
    "        for j in range(len(percentile[i])):\n",
    "            totalfori += percentile[i][j]\n",
    "        totalfori//= len(percentile[i])\n",
    "        percentile[i] = totalfori\n",
    "    fr_this_time = []\n",
    "    for i in range(50):\n",
    "        fr_this_time.append(0)\n",
    "    for i in range(50):\n",
    "        totalfori = 0\n",
    "        for j in range(2):\n",
    "            totalfori+=percentile[2*i+j]\n",
    "        totalfori/=2\n",
    "        fr_this_time[i] = totalfori\n",
    "    left = []\n",
    "    for i in range(50):\n",
    "        left.append(i)\n",
    "    height = fr_this_time\n",
    "    tick_label = ['0','','','','','10','','','','','20','','','','','30','','','','', '40','','','','',\n",
    "                 '50','','','','','60','','','','','70','','','','','80','','','','', '90','','','','']\n",
    "    plt.bar(left, height, tick_label = tick_label, width = 1, color = 'black')\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel(\"Global Cluster Size Percentiles\")\n",
    "    plt.ylabel(\"Percent of Protein Clusters in Percentile\")\n",
    "    plt.title(\"Global Cluster Size Distribution\")\n",
    "    plt.show()\n",
    "    \n",
    "def get_global_actual_bucket_4(results):\n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append([])\n",
    "    for result in results:\n",
    "        for p in range(len(result.global_percentile_actual)):\n",
    "            percentile[p].append(result.global_percentile_actual[p])\n",
    "    for i in range(len(percentile)):\n",
    "        totalfori = 0\n",
    "        for j in range(len(percentile[i])):\n",
    "            totalfori += percentile[i][j]\n",
    "        totalfori//= len(percentile[i])\n",
    "        percentile[i] = totalfori\n",
    "    fr_this_time = []\n",
    "    for i in range(25):\n",
    "        fr_this_time.append(0)\n",
    "    for i in range(25):\n",
    "        totalfori = 0\n",
    "        for j in range(4):\n",
    "            totalfori+=percentile[4*i+j]\n",
    "        totalfori/=4\n",
    "        fr_this_time[i] = totalfori\n",
    "    left = []\n",
    "    for i in range(25):\n",
    "        left.append(i)\n",
    "    height = fr_this_time\n",
    "    tick_label = ['0','','','','','20','','','','','40','','','','','60','','','','', '80','','','','']\n",
    "    plt.bar(left, height, tick_label = tick_label, width = 1, color = 'black')\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel(\"Global Cluster Size Percentiles\")\n",
    "    plt.ylabel(\"Percent of Protein Clusters in Percentile\")\n",
    "    plt.title(\"Global Cluster Size Distribution\")\n",
    "    plt.show()\n",
    "    \n",
    "def get_global_actual_bucket_5(results):\n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append([])\n",
    "    for result in results:\n",
    "        for p in range(len(result.global_percentile_actual)):\n",
    "            percentile[p].append(result.global_percentile_actual[p])\n",
    "    for i in range(len(percentile)):\n",
    "        totalfori = 0\n",
    "        for j in range(len(percentile[i])):\n",
    "            totalfori += percentile[i][j]\n",
    "        totalfori//= len(percentile[i])\n",
    "        percentile[i] = totalfori\n",
    "    fr_this_time = []\n",
    "    for i in range(20):\n",
    "        fr_this_time.append(0)\n",
    "    for i in range(20):\n",
    "        totalfori = 0\n",
    "        for j in range(5):\n",
    "            totalfori+=percentile[5*i+j]\n",
    "        totalfori/=5\n",
    "        fr_this_time[i] = totalfori\n",
    "    left = []\n",
    "    for i in range(20):\n",
    "        left.append(i)\n",
    "    height = fr_this_time\n",
    "    tick_label = ['0','5','10','15','20','25','30','35','40','45','50','55','60','65','70','75','80','85','90','95']\n",
    "    plt.bar(left, height, tick_label = tick_label, width = 1, color = 'black')\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel(\"Global Cluster Size Percentiles\")\n",
    "    plt.ylabel(\"Percent of Protein Clusters in Percentile\")\n",
    "    plt.title(\"Global Cluster Size Distribution\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f2f47b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms of true positive predictions of protein clusters in global cluster size distribution\n",
    "def get_global_bucket_1(results):\n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append([])\n",
    "    for result in results:\n",
    "        for p in range(len(result.global_percentile)):\n",
    "            percentile[p].append(result.global_percentile[p])\n",
    "    for i in range(len(percentile)):\n",
    "        totalfori = 0\n",
    "        for j in range(len(percentile[i])):\n",
    "            totalfori += percentile[i][j]\n",
    "        totalfori//=len(percentile[i])\n",
    "        percentile[i] = totalfori\n",
    "    left = []\n",
    "    for i in range(100):\n",
    "        left.append(i)\n",
    "    height = percentile\n",
    "    tick_label = ['0','5','10','15','20','25','30','35','40','45','50','55','60','65','70','75','80','85','90','95']\n",
    "    plt.bar(left, height, width = 1, color = results[0].global_color)\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel(\"Specificity of Function Assignment\")\n",
    "    plt.ylabel(\"Frequency of Correct Assignment\")\n",
    "    plt.title(results[0].global_title)\n",
    "    plt.show()\n",
    "    \n",
    "def get_global_bucket_2(results):\n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append([])\n",
    "    for result in results:\n",
    "        for p in range(len(result.global_percentile)):\n",
    "            percentile[p].append(result.global_percentile[p])\n",
    "    for i in range(len(percentile)):\n",
    "        totalfori = 0\n",
    "        for j in range(len(percentile[i])):\n",
    "            totalfori += percentile[i][j]\n",
    "        totalfori//=len(percentile[i])\n",
    "        percentile[i] = totalfori\n",
    "    fr_this_time = []\n",
    "    for i in range(50):\n",
    "        fr_this_time.append(0)\n",
    "    for i in range(50):\n",
    "        totalfori = 0\n",
    "        for j in range(2):\n",
    "            totalfori+=percentile[2*i+j]\n",
    "        totalfori/=2\n",
    "        fr_this_time[i] = totalfori\n",
    "    left = []\n",
    "    for i in range(50):\n",
    "        left.append(i)\n",
    "    height = fr_this_time\n",
    "    tick_label = ['0','','','','','10','','','','','20','','','','','30','','','','', '40','','','','',\n",
    "                 '50','','','','','60','','','','','70','','','','','80','','','','', '90','','','','']\n",
    "    plt.bar(left, height, tick_label = tick_label, width = 1, color = results[0].global_color)\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel(\"Specificity of Function Assignment\")\n",
    "    plt.ylabel(\"Frequency of Correct Assignment\")\n",
    "    plt.title(results[0].global_title)\n",
    "    plt.show()\n",
    "\n",
    "def get_global_bucket_4(results):\n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append([])\n",
    "    for result in results:\n",
    "        for p in range(len(result.global_percentile)):\n",
    "            percentile[p].append(result.global_percentile[p])\n",
    "    for i in range(len(percentile)):\n",
    "        totalfori = 0\n",
    "        for j in range(len(percentile[i])):\n",
    "            totalfori += percentile[i][j]\n",
    "        totalfori//=len(percentile[i])\n",
    "        percentile[i] = totalfori\n",
    "    fr_this_time = []\n",
    "    for i in range(25):\n",
    "        fr_this_time.append(0)\n",
    "    for i in range(25):\n",
    "        totalfori = 0\n",
    "        for j in range(4):\n",
    "            totalfori+=percentile[4*i+j]\n",
    "        totalfori/=4\n",
    "        fr_this_time[i] = totalfori\n",
    "    left = []\n",
    "    for i in range(25):\n",
    "        left.append(i)\n",
    "    height = fr_this_time\n",
    "    tick_label = ['0','','','','','20','','','','','40','','','','','60','','','','', '80','','','','']\n",
    "    plt.bar(left, height, tick_label = tick_label, width = 1, color = results[0].global_color)\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel(\"Specificity of Function Assignment\")\n",
    "    plt.ylabel(\"Frequency of Correct Assignment\")\n",
    "    plt.title(results[0].global_title)\n",
    "    plt.show() \n",
    "\n",
    "def get_global_bucket_5(results):\n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append([])\n",
    "    for result in results:\n",
    "        for p in range(len(result.global_percentile)):\n",
    "            percentile[p].append(result.global_percentile[p])\n",
    "    for i in range(len(percentile)):\n",
    "        totalfori = 0\n",
    "        for j in range(len(percentile[i])):\n",
    "            totalfori += percentile[i][j]\n",
    "        totalfori//=len(percentile[i])\n",
    "        percentile[i] = totalfori\n",
    "    fr_this_time = []\n",
    "    for i in range(20):\n",
    "        fr_this_time.append(0)\n",
    "    for i in range(20):\n",
    "        totalfori = 0\n",
    "        for j in range(5):\n",
    "            totalfori+=percentile[5*i+j]\n",
    "        totalfori/=5\n",
    "        fr_this_time[i] = totalfori\n",
    "    left = []\n",
    "    for i in range(20):\n",
    "        left.append(i)\n",
    "    height = fr_this_time\n",
    "    tick_label = ['0','5','10','15','20','25','30','35','40','45','50','55','60','65','70','75','80','85','90','95']\n",
    "    plt.bar(left, height, tick_label = tick_label, width = 1, color = results[0].global_color)\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel(\"Specificity of Function Assignment\")\n",
    "    plt.ylabel(\"Frequency of Correct Assignment\")\n",
    "    plt.title(results[0].global_title)\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e8abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms of true positive predictions of protein clusters in local cluster size distribution\n",
    "def get_local_bucket_1(results):\n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append([])\n",
    "    for i in range(100):\n",
    "        for result in results:\n",
    "            percentile[i].append(result.local_percentile[i]*100)\n",
    "    for i in range(len(percentile)):\n",
    "        totalfori = 0\n",
    "        for j in range(len(percentile[i])):\n",
    "            totalfori += percentile[i][j]\n",
    "        totalfori//=len(percentile[i])\n",
    "        percentile[i] = totalfori\n",
    "    left = []\n",
    "    for i in range(100):\n",
    "        left.append(i)\n",
    "    height = percentile\n",
    "    plt.bar(left, height, width = 1, color = results[0].local_color)\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel(\"Specificity of Function Assignment\")\n",
    "    plt.ylabel(\"Frequency of Correct Assignment\")\n",
    "    plt.title(results[0].local_title)\n",
    "    plt.show()\n",
    "\n",
    "def get_local_bucket_2(results):\n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append([])\n",
    "    for i in range(100):\n",
    "        for result in results:\n",
    "            percentile[i].append(result.local_percentile[i]*100)\n",
    "    for i in range(len(percentile)):\n",
    "        totalfori = 0\n",
    "        for j in range(len(percentile[i])):\n",
    "            totalfori += percentile[i][j]\n",
    "        totalfori//=len(percentile[i])\n",
    "        percentile[i] = totalfori\n",
    "    fr_this_time = []\n",
    "    for i in range(50):\n",
    "        fr_this_time.append(0)\n",
    "    for i in range(50):\n",
    "        totalfori = 0\n",
    "        for j in range(2):\n",
    "            totalfori+=percentile[2*i+j]\n",
    "        totalfori/=2\n",
    "        fr_this_time[i] = totalfori\n",
    "    left = []\n",
    "    for i in range(50):\n",
    "        left.append(i)\n",
    "    height = fr_this_time\n",
    "    tick_label = ['0','','','','','10','','','','','20','','','','','30','','','','', '40','','','','',\n",
    "                 '50','','','','','60','','','','','70','','','','','80','','','','', '90','','','','']\n",
    "    plt.bar(left, height, tick_label = tick_label, width = 1, color = results[0].local_color)\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel(\"Specificity of Function Assignment\")\n",
    "    plt.ylabel(\"Frequency of Correct Assignment\")\n",
    "    plt.title(results[0].local_title)\n",
    "    plt.show()\n",
    "\n",
    "def get_local_bucket_4(results):\n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append([])\n",
    "    for i in range(100):\n",
    "        for result in results:\n",
    "            percentile[i].append(result.local_percentile[i]*100)\n",
    "    for i in range(len(percentile)):\n",
    "        totalfori = 0\n",
    "        for j in range(len(percentile[i])):\n",
    "            totalfori += percentile[i][j]\n",
    "        totalfori//=len(percentile[i])\n",
    "        percentile[i] = totalfori\n",
    "    fr_this_time = []\n",
    "    for i in range(25):\n",
    "        fr_this_time.append(0)\n",
    "    for i in range(25):\n",
    "        totalfori = 0\n",
    "        for j in range(4):\n",
    "            totalfori+=percentile[4*i+j]\n",
    "        totalfori/=4\n",
    "        fr_this_time[i] = totalfori\n",
    "    left = []\n",
    "    for i in range(25):\n",
    "        left.append(i)\n",
    "    height = fr_this_time\n",
    "    tick_label = ['0','','','','','20','','','','','40','','','','','60','','','','', '80','','','','']\n",
    "    plt.bar(left, height, tick_label = tick_label, width = 1, color = results[0].local_color)\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel(\"Specificity of Function Assignment\")\n",
    "    plt.ylabel(\"Frequency of Correct Assignment\")\n",
    "    plt.title(results[0].local_title)\n",
    "    plt.show()\n",
    "\n",
    "def get_local_bucket_5(results):\n",
    "    percentile = []\n",
    "    for i in range(100):\n",
    "        percentile.append([])\n",
    "    for i in range(100):\n",
    "        for result in results:\n",
    "            percentile[i].append(result.local_percentile[i]*100)\n",
    "    for i in range(len(percentile)):\n",
    "        totalfori = 0\n",
    "        for j in range(len(percentile[i])):\n",
    "            totalfori += percentile[i][j]\n",
    "        totalfori//=len(percentile[i])\n",
    "        percentile[i] = totalfori\n",
    "    fr_this_time = []\n",
    "    for i in range(20):\n",
    "        fr_this_time.append(0)\n",
    "    for i in range(20):\n",
    "        totalfori = 0\n",
    "        for j in range(5):\n",
    "            totalfori+=percentile[5*i+j]\n",
    "        totalfori/=5\n",
    "        fr_this_time[i] = totalfori\n",
    "    left = []\n",
    "    for i in range(20):\n",
    "        left.append(i)\n",
    "    height = fr_this_time\n",
    "    tick_label = ['0','5','10','15','20','25','30','35','40','45','50','55','60','65','70','75','80','85','90','95']\n",
    "    plt.bar(left, height, tick_label = tick_label, width = 1, color = results[0].local_color)\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel(\"Specificity of Function Assignment\")\n",
    "    plt.ylabel(\"Frequency of Correct Assignment\")\n",
    "    plt.title(results[0].local_title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36ed0bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# majority results held here\n",
    "majority_list_radius_1 = []\n",
    "majority_list_radius_2 = []\n",
    "majority_list_radius_3 = []\n",
    "majority_list_radius_4 = []\n",
    "majority_list_radius_5 = []\n",
    "\n",
    "# flow results held here\n",
    "flow_list_radius_1 = []\n",
    "flow_list_radius_2 = []\n",
    "flow_list_radius_3 = []\n",
    "flow_list_radius_4 = []\n",
    "flow_list_radius_5 = []\n",
    "\n",
    "# align results held here\n",
    "align_list_radius_1 = []\n",
    "align_list_radius_2 = []\n",
    "align_list_radius_3 = []\n",
    "align_list_radius_4 = []\n",
    "align_list_radius_5 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2698cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RADIUS 1\n",
      "ITER 1 / 50\n",
      "['362663.ECP_3575', '362663.ECP_0089', '362663.ECP_2491', '362663.ECP_0159', '362663.ECP_0672']\n",
      "ITER 2 / 50\n",
      "ITER 3 / 50\n",
      "ITER 4 / 50\n",
      "['362663.ECP_2056', '362663.ECP_3657', '362663.ECP_0723', '362663.ECP_3106', '362663.ECP_0766']\n",
      "ITER 5 / 50\n",
      "['362663.ECP_0751', '362663.ECP_1101', '362663.ECP_1258', '362663.ECP_2153', '362663.ECP_4179']\n",
      "starting majority\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 12\n",
      "WORKING NBORHOOD SIZE: 15\n",
      "WORKING NBORHOOD SIZE: 15\n",
      "WORKING NBORHOOD SIZE: 13\n",
      "WORKING NBORHOOD SIZE: 1\n",
      "did majority\n",
      "starting ff\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 56\n",
      "did majority\n",
      "ITER 6 / 50\n",
      "['362663.ECP_1396', '362663.ECP_4552', '362663.ECP_3109', '362663.ECP_0183', '362663.ECP_1400']\n",
      "ITER 7 / 50\n",
      "ITER 8 / 50\n"
     ]
    }
   ],
   "source": [
    "print(\"RADIUS 1\")\n",
    "for i in range(50):\n",
    "    print(\"ITER {} / {}\".format(i+1, 50))\n",
    "    \n",
    "    try:\n",
    "        results = RawResults(\"ecoli\", 5, 1)\n",
    "        majority_results = MajorityApproachResults(results)\n",
    "        majority_list_radius_1.append(majority_results)\n",
    "        flow_results = FunctionalFlowResults(results)\n",
    "        flow_list_radius_1.append(flow_results)\n",
    "        align_results = AlignmentApproachResults(results)\n",
    "        align_list_radius_1.append(align_results)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51299aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RADIUS 2\n",
      "ITER 1 / 50\n",
      "['362663.ECP_3981']\n",
      "starting majority\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 114\n",
      "did majority\n",
      "starting ff\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 114\n",
      "ITER 2 / 50\n",
      "ITER 3 / 50\n",
      "['362663.ECP_2341']\n",
      "ITER 4 / 50\n",
      "ITER 5 / 50\n",
      "ITER 6 / 50\n",
      "ITER 7 / 50\n",
      "ITER 8 / 50\n",
      "ITER 9 / 50\n",
      "ITER 10 / 50\n",
      "ITER 11 / 50\n",
      "ITER 12 / 50\n",
      "ITER 13 / 50\n",
      "ITER 14 / 50\n",
      "ITER 15 / 50\n",
      "ITER 16 / 50\n",
      "ITER 17 / 50\n",
      "ITER 18 / 50\n",
      "ITER 19 / 50\n",
      "ITER 20 / 50\n",
      "ITER 21 / 50\n",
      "ITER 22 / 50\n",
      "ITER 23 / 50\n",
      "ITER 24 / 50\n",
      "['362663.ECP_1754']\n"
     ]
    }
   ],
   "source": [
    "print(\"RADIUS 2\")\n",
    "for i in range(50):\n",
    "    print(\"ITER {} / {}\".format(i+1, 50))\n",
    "    \n",
    "    try:\n",
    "        results = RawResults(\"ecoli\", 1, 2)\n",
    "        majority_results = MajorityApproachResults(results)\n",
    "        majority_list_radius_2.append(majority_results)\n",
    "        flow_results = FunctionalFlowResults(results)\n",
    "        flow_list_radius_2.append(flow_results)\n",
    "#         align_results = AlignmentApproachResults(results)\n",
    "#         align_list_radius_2.append(align_results)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a86652b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RADIUS 3\n",
      "ITER 1 / 50\n",
      "['362663.ECP_4454']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1706\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1706\n",
      "ITER 2 / 50\n",
      "['362663.ECP_0268']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 168\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 168\n",
      "ITER 3 / 50\n",
      "['362663.ECP_4001']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 80\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 80\n",
      "ITER 4 / 50\n",
      "['362663.ECP_2125']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 27\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 27\n",
      "ITER 5 / 50\n",
      "['362663.ECP_3012']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 59\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 59\n",
      "ITER 6 / 50\n",
      "['362663.ECP_2584']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 503\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 503\n",
      "ITER 7 / 50\n",
      "['362663.ECP_2545']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 664\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 664\n",
      "ITER 8 / 50\n",
      "['362663.ECP_4197']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1720\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1720\n",
      "ITER 9 / 50\n",
      "['362663.ECP_0590']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1591\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1591\n",
      "ITER 10 / 50\n",
      "['362663.ECP_2715']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 6\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 6\n",
      "ITER 11 / 50\n",
      "['362663.ECP_2379']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1929\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1929\n",
      "ITER 12 / 50\n",
      "['362663.ECP_1711']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1741\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1741\n",
      "ITER 13 / 50\n",
      "['362663.ECP_2786']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 175\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 175\n",
      "ITER 14 / 50\n",
      "['362663.ECP_2721']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 548\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 548\n",
      "ITER 15 / 50\n",
      "['362663.ECP_0300']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 299\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 299\n",
      "ITER 16 / 50\n",
      "['362663.ECP_2605']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 429\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 429\n",
      "ITER 17 / 50\n",
      "['362663.ECP_1681']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 190\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 190\n",
      "ITER 18 / 50\n",
      "['362663.ECP_3626']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 797\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 797\n",
      "ITER 19 / 50\n",
      "['362663.ECP_1698']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 73\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 73\n",
      "ITER 20 / 50\n",
      "['362663.ECP_4059']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1924\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1924\n",
      "ITER 21 / 50\n",
      "['362663.ECP_2296']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 527\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 527\n",
      "ITER 22 / 50\n",
      "['362663.ECP_3268']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 963\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 963\n",
      "ITER 23 / 50\n",
      "['362663.ECP_2087']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 687\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 687\n",
      "ITER 24 / 50\n",
      "['362663.ECP_0897']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1024\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1024\n",
      "ITER 25 / 50\n",
      "['362663.ECP_1716']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1033\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1033\n",
      "ITER 26 / 50\n",
      "['362663.ECP_0646']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 14\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 14\n",
      "ITER 27 / 50\n",
      "['362663.ECP_1540']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 2\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 2\n",
      "ITER 28 / 50\n",
      "['362663.ECP_4757']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1654\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1654\n",
      "ITER 29 / 50\n",
      "['362663.ECP_1618']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 677\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 677\n",
      "ITER 30 / 50\n",
      "['362663.ECP_1155']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 2\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 2\n",
      "ITER 31 / 50\n",
      "['362663.ECP_3149']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 922\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 922\n",
      "ITER 32 / 50\n",
      "['362663.ECP_1643']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 607\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 607\n",
      "ITER 33 / 50\n",
      "['362663.ECP_1760']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 737\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 737\n",
      "ITER 34 / 50\n",
      "['362663.ECP_0992']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 837\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 837\n",
      "ITER 35 / 50\n",
      "['362663.ECP_1022']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 110\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 110\n",
      "ITER 36 / 50\n",
      "['362663.ECP_1882']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 747\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 747\n",
      "ITER 37 / 50\n",
      "['362663.ECP_0236']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 92\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 92\n",
      "ITER 38 / 50\n",
      "['362663.ECP_1117']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 214\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 214\n",
      "ITER 39 / 50\n",
      "['362663.ECP_4331']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 221\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 221\n",
      "ITER 40 / 50\n",
      "['362663.ECP_1599']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 538\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 538\n",
      "ITER 41 / 50\n",
      "['362663.ECP_3240']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1794\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1794\n",
      "ITER 42 / 50\n",
      "['362663.ECP_2740']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 173\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 173\n",
      "ITER 43 / 50\n",
      "['362663.ECP_4050']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 370\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 370\n",
      "ITER 44 / 50\n",
      "['362663.ECP_2351']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1600\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1600\n",
      "ITER 45 / 50\n",
      "['362663.ECP_0914']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1887\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1887\n",
      "ITER 46 / 50\n",
      "['362663.ECP_1175']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 400\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 400\n",
      "ITER 47 / 50\n",
      "['362663.ECP_1300']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1658\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1658\n",
      "ITER 48 / 50\n",
      "['362663.ECP_4407']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 66\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 66\n",
      "ITER 49 / 50\n",
      "['362663.ECP_3164']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 377\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 377\n",
      "ITER 50 / 50\n",
      "['362663.ECP_2467']\n",
      "---- MAJORITY APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1626\n",
      "---- FLOW APPROACH ----\n",
      "WORKING NBORHOOD SIZE: 1626\n"
     ]
    }
   ],
   "source": [
    "print(\"RADIUS 3\")\n",
    "for i in range(50):\n",
    "    print(\"ITER {} / {}\".format(i+1, 50))\n",
    "    \n",
    "    try:\n",
    "        results = RawResults(\"ecoli\", 1, 3)\n",
    "        majority_results = MajorityApproachResults(results)\n",
    "        majority_list_radius_3.append(majority_results)\n",
    "        flow_results = FunctionalFlowResults(results)\n",
    "        flow_list_radius_3.append(flow_results)\n",
    "#         align_results = AlignmentApproachResults(results)\n",
    "#         align_list_radius_3.append(align_results)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24067376",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RADIUS 4\")\n",
    "for i in range(50):\n",
    "    print(\"ITER {} / {}\".format(i+1, 50))\n",
    "    \n",
    "    try:\n",
    "        results = RawResults(\"ecoli\", 1, 4)\n",
    "        majority_results = MajorityApproachResults(results)\n",
    "        majority_list_radius_4.append(majority_results)\n",
    "        flow_results = FunctionalFlowResults(results)\n",
    "        flow_list_radius_4.append(flow_results)\n",
    "#         align_results = AlignmentApproachResults(results)\n",
    "#         align_list_radius_4.append(align_results)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596bffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RADIUS 5\")\n",
    "for i in range(50):\n",
    "    print(\"ITER {} / {}\".format(i+1, 50))\n",
    "    \n",
    "    try:\n",
    "        results = RawResults(\"ecoli\", 1, 5)\n",
    "        majority_results = MajorityApproachResults(results)\n",
    "        majority_list_radius_5.append(majority_results)\n",
    "        flow_results = FunctionalFlowResults(results)\n",
    "        flow_list_radius_5.append(flow_results)\n",
    "#         align_results = AlignmentApproachResults(results)\n",
    "#         align_list_radius_5.append(align_results)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7901ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global stats \n",
    "get_global_actual_bucket_1(majority_list_radius_1)\n",
    "get_global_actual_bucket_2(majority_list_radius_1)\n",
    "get_global_actual_bucket_4(majority_list_radius_1)\n",
    "get_global_actual_bucket_5(majority_list_radius_1)\n",
    "\n",
    "# majority radius 1\n",
    "get_global_bucket_1(majority_list_radius_1)\n",
    "get_global_bucket_2(majority_list_radius_1)\n",
    "get_global_bucket_4(majority_list_radius_1)\n",
    "get_global_bucket_5(majority_list_radius_1)\n",
    "\n",
    "get_local_bucket_1(majority_list_radius_1)\n",
    "get_local_bucket_2(majority_list_radius_1)\n",
    "get_local_bucket_4(majority_list_radius_1)\n",
    "get_local_bucket_5(majority_list_radius_1)\n",
    "\n",
    "# flow radius 1 \n",
    "get_global_bucket_1(flow_list_radius_1)\n",
    "get_global_bucket_2(flow_list_radius_1)\n",
    "get_global_bucket_4(flow_list_radius_1)\n",
    "get_global_bucket_5(flow_list_radius_1)\n",
    "\n",
    "get_local_bucket_1(flow_list_radius_1)\n",
    "get_local_bucket_2(flow_list_radius_1)\n",
    "get_local_bucket_4(flow_list_radius_1)\n",
    "get_local_bucket_5(flow_list_radius_1)\n",
    "\n",
    "# align radius 1\n",
    "get_global_bucket_1(align_list_radius_1)\n",
    "get_global_bucket_2(align_list_radius_1)\n",
    "get_global_bucket_4(align_list_radius_1)\n",
    "get_global_bucket_5(align_list_radius_1)\n",
    "\n",
    "get_local_bucket_1(align_list_radius_1)\n",
    "get_local_bucket_2(align_list_radius_1)\n",
    "get_local_bucket_4(align_list_radius_1)\n",
    "get_local_bucket_5(align_list_radius_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e96eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global stats \n",
    "get_global_actual_bucket_1(majority_list_radius_2)\n",
    "get_global_actual_bucket_2(majority_list_radius_2)\n",
    "get_global_actual_bucket_4(majority_list_radius_2)\n",
    "get_global_actual_bucket_5(majority_list_radius_2)\n",
    "\n",
    "# majority radius 2\n",
    "get_global_bucket_1(majority_list_radius_2)\n",
    "get_global_bucket_2(majority_list_radius_2)\n",
    "get_global_bucket_4(majority_list_radius_2)\n",
    "get_global_bucket_5(majority_list_radius_2)\n",
    "\n",
    "get_local_bucket_1(majority_list_radius_2)\n",
    "get_local_bucket_2(majority_list_radius_2)\n",
    "get_local_bucket_4(majority_list_radius_2)\n",
    "get_local_bucket_5(majority_list_radius_2)\n",
    "\n",
    "# flow radius 2 \n",
    "get_global_bucket_1(flow_list_radius_2)\n",
    "get_global_bucket_2(flow_list_radius_2)\n",
    "get_global_bucket_4(flow_list_radius_2)\n",
    "get_global_bucket_5(flow_list_radius_2)\n",
    "\n",
    "get_local_bucket_1(flow_list_radius_2)\n",
    "get_local_bucket_2(flow_list_radius_2)\n",
    "get_local_bucket_4(flow_list_radius_2)\n",
    "get_local_bucket_5(flow_list_radius_2)\n",
    "\n",
    "# align radius 2\n",
    "get_global_bucket_1(align_list_radius_2)\n",
    "get_global_bucket_2(aign_list_radius_2)\n",
    "get_global_bucket_4(align_list_radius_2)\n",
    "get_global_bucket_5(align_list_radius_2)\n",
    "\n",
    "get_local_bucket_1(align_list_radius_2)\n",
    "get_local_bucket_2(align_list_radius_2)\n",
    "get_local_bucket_4(align_list_radius_2)\n",
    "get_local_bucket_5(align_list_radius_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc8997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global stats \n",
    "get_global_actual_bucket_1(majority_list_radius_3)\n",
    "get_global_actual_bucket_2(majority_list_radius_3)\n",
    "get_global_actual_bucket_4(majority_list_radius_3)\n",
    "get_global_actual_bucket_5(majority_list_radius_3)\n",
    "\n",
    "# majority radius 3\n",
    "get_global_bucket_1(majority_list_radius_3)\n",
    "get_global_bucket_2(majority_list_radius_3)\n",
    "get_global_bucket_4(majority_list_radius_3)\n",
    "get_global_bucket_5(majority_list_radius_3)\n",
    "\n",
    "get_local_bucket_1(majority_list_radius_3)\n",
    "get_local_bucket_2(majority_list_radius_3)\n",
    "get_local_bucket_4(majority_list_radius_3)\n",
    "get_local_bucket_5(majority_list_radius_3)\n",
    "\n",
    "# flow radius 3\n",
    "get_global_bucket_1(flow_list_radius_3)\n",
    "get_global_bucket_2(flow_list_radius_3)\n",
    "get_global_bucket_4(flow_list_radius_3)\n",
    "get_global_bucket_5(flow_list_radius_3)\n",
    "\n",
    "get_local_bucket_1(flow_list_radius_3)\n",
    "get_local_bucket_2(flow_list_radius_3)\n",
    "get_local_bucket_4(flow_list_radius_3)\n",
    "get_local_bucket_5(flow_list_radius_3)\n",
    "\n",
    "# align radius 3\n",
    "get_global_bucket_1(align_list_radius_3)\n",
    "get_global_bucket_2(align_list_radius_3)\n",
    "get_global_bucket_4(align_list_radius_3)\n",
    "get_global_bucket_5(align_list_radius_3)\n",
    "\n",
    "get_local_bucket_1(align_list_radius_3)\n",
    "get_local_bucket_2(align_list_radius_3)\n",
    "get_local_bucket_4(align_list_radius_3)\n",
    "get_local_bucket_5(align_list_radius_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f90703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global stats \n",
    "get_global_actual_bucket_1(majority_list_radius_4)\n",
    "get_global_actual_bucket_2(majority_list_radius_4)\n",
    "get_global_actual_bucket_4(majority_list_radius_4)\n",
    "get_global_actual_bucket_5(majority_list_radius_4)\n",
    "\n",
    "# majority radius 4\n",
    "get_global_bucket_1(majority_list_radius_4)\n",
    "get_global_bucket_2(majority_list_radius_4)\n",
    "get_global_bucket_4(majority_list_radius_4)\n",
    "get_global_bucket_5(majority_list_radius_4)\n",
    "\n",
    "get_local_bucket_1(majority_list_radius_4)\n",
    "get_local_bucket_2(majority_list_radius_4)\n",
    "get_local_bucket_4(majority_list_radius_4)\n",
    "get_local_bucket_5(majority_list_radius_4)\n",
    "\n",
    "# flow radius 4\n",
    "get_global_bucket_1(flow_list_radius_4)\n",
    "get_global_bucket_2(flow_list_radius_4)\n",
    "get_global_bucket_4(flow_list_radius_4)\n",
    "get_global_bucket_5(flow_list_radius_4)\n",
    "\n",
    "get_local_bucket_1(flow_list_radius_4)\n",
    "get_local_bucket_2(flow_list_radius_4)\n",
    "get_local_bucket_4(flow_list_radius_4)\n",
    "get_local_bucket_5(flow_list_radius_4)\n",
    "\n",
    "# align radius 4\n",
    "get_global_bucket_1(align_list_radius_4)\n",
    "get_global_bucket_2(align_list_radius_4)\n",
    "get_global_bucket_4(align_list_radius_4)\n",
    "get_global_bucket_5(align_list_radius_4)\n",
    "\n",
    "get_local_bucket_1(align_list_radius_4)\n",
    "get_local_bucket_2(align_list_radius_4)\n",
    "get_local_bucket_4(align_list_radius_4)\n",
    "get_local_bucket_5(align_list_radius_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5937f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global stats \n",
    "get_global_actual_bucket_1(majority_list_radius_5)\n",
    "get_global_actual_bucket_2(majority_list_radius_5)\n",
    "get_global_actual_bucket_4(majority_list_radius_5)\n",
    "get_global_actual_bucket_5(majority_list_radius_5)\n",
    "\n",
    "# majority radius 5\n",
    "get_global_bucket_1(majority_list_radius_5)\n",
    "get_global_bucket_2(majority_list_radius_5)\n",
    "get_global_bucket_4(majority_list_radius_5)\n",
    "get_global_bucket_5(majority_list_radius_5)\n",
    "\n",
    "get_local_bucket_1(majority_list_radius_5)\n",
    "get_local_bucket_2(majority_list_radius_5)\n",
    "get_local_bucket_4(majority_list_radius_5)\n",
    "get_local_bucket_5(majority_list_radius_5)\n",
    "\n",
    "# flow radius 5\n",
    "get_global_bucket_1(flow_list_radius_5)\n",
    "get_global_bucket_2(flow_list_radius_5)\n",
    "get_global_bucket_4(flow_list_radius_5)\n",
    "get_global_bucket_5(flow_list_radius_5)\n",
    "\n",
    "get_local_bucket_1(flow_list_radius_5)\n",
    "get_local_bucket_2(flow_list_radius_5)\n",
    "get_local_bucket_4(flow_list_radius_5)\n",
    "get_local_bucket_5(flow_list_radius_5)\n",
    "\n",
    "# align radius 5\n",
    "get_global_bucket_1(align_list_radius_5)\n",
    "get_global_bucket_2(align_list_radius_5)\n",
    "get_global_bucket_4(align_list_radius_5)\n",
    "get_global_bucket_5(align_list_radius_5)\n",
    "\n",
    "get_local_bucket_1(align_list_radius_5)\n",
    "get_local_bucket_2(align_list_radius_5)\n",
    "get_local_bucket_4(align_list_radius_5)\n",
    "get_local_bucket_5(align_list_radius_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2804d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used currently\n",
    "def score(p, true_pos, false_pos, false_neg, tp_reward, fp_penalty, fn_penalty, annotations):\n",
    "    all_scores = []\n",
    "    for i in range(len(p)):\n",
    "        score_sum = 0\n",
    "        score_sum += true_pos[i][1]*tp_reward\n",
    "        score_sum += false_pos[i][1]*fp_penalty\n",
    "        score_sum += false_neg[i][1]*fn_penalty\n",
    "        score_percent = score_sum/len(annotations[p[i]])\n",
    "        all_scores.append(score_percent)\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c32d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not currently used\n",
    "def get_accuracy(results):\n",
    "    temp_dict = dict()\n",
    "    temp_set = set()\n",
    "    x1 = []\n",
    "    y1 = []\n",
    "    for result in results:\n",
    "        temp_set.add(result.r)\n",
    "    for result in results:\n",
    "        temp = 0\n",
    "        for p in range(len(result.p)):\n",
    "            temp += ((result.true_positive_majority[p][1])/len(result.annotation_dict[result.p[p]]))\n",
    "        temp_dict[result.r] = (temp/len(result.p))\n",
    "    for x in temp_dict:\n",
    "        x1.append(x)\n",
    "        y1.append(temp_dict[x])\n",
    "    plt.plot(x1, y1, label = \"Majority Approach\")\n",
    "\n",
    "    temp_dict = dict()\n",
    "    temp_set = set()\n",
    "    x2 = []\n",
    "    y2 = []\n",
    "    for result in results:\n",
    "        temp_set.add(result.r)\n",
    "    for result in results:\n",
    "        temp = 0\n",
    "        for p in range(len(result.p)):\n",
    "            temp += ((result.true_positive_flow[p][1])/len(result.annotation_dict[result.p[p]]))\n",
    "        temp_dict[result.r] = (temp/len(result.p))\n",
    "    for x in temp_dict:\n",
    "        x2.append(x)\n",
    "        y2.append(temp_dict[x])\n",
    "    print(x2, y2)\n",
    "    plt.plot(x2, y2, label = \"Functional Flow\")\n",
    "\n",
    "    temp_dict = dict()\n",
    "    temp_set = set()\n",
    "    x3 = []\n",
    "    y3 = []\n",
    "    for result in results:\n",
    "        temp_set.add(result.r)\n",
    "    for result in results:\n",
    "        temp = 0\n",
    "        for p in range(len(result.p)):\n",
    "            temp += ((result.true_positive_align[p][1])/len(result.annotation_dict[result.p[p]]))\n",
    "        temp_dict[result.r] = (temp/len(result.p))\n",
    "    for x in temp_dict:\n",
    "        x3.append(x)\n",
    "        y2.append(temp_dict[x])\n",
    "    plt.plot(x3, y3, label = \"Alignment Approach\")\n",
    "\n",
    "    plt.xlabel(\"radius r or timestep t\")\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy Comparison')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f1a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for presentation\n",
    "# plots proximity v intersection of function\n",
    "left = [1,2,3,4]\n",
    "height = [83, 64, 55, 47]\n",
    "tick_label = ['r=1', 'r=2', 'r=3', 'r=4']\n",
    "plt.bar(left, height, tick_label = tick_label,\n",
    "        width = 1, color = ['orange', 'gold'])\n",
    "plt.xlabel('proximity of neighbors')\n",
    "plt.ylabel('intersection of function')\n",
    "plt.title('')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f23370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
